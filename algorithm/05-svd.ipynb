{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Surprise库的SVD实现不直接支持增量训练，不过可以通过其他方法实现类似效果。我们可以使用逐步更新模型的方式来模拟增量训练。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca2b8ff53f49aece"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d747cbdae4068f6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-07T06:28:39.050211Z",
     "start_time": "2024-08-07T06:28:38.886544Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 45\u001B[0m\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m algo\n\u001B[1;32m     44\u001B[0m \u001B[38;5;66;03m# 数据采样\u001B[39;00m\n\u001B[0;32m---> 45\u001B[0m sampled_data \u001B[38;5;241m=\u001B[39m \u001B[43msample_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;66;03m# 数据划分\u001B[39;00m\n\u001B[1;32m     48\u001B[0m trainset, testset \u001B[38;5;241m=\u001B[39m train_test_split(sampled_data, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.25\u001B[39m)\n",
      "Cell \u001B[0;32mIn[2], line 23\u001B[0m, in \u001B[0;36msample_data\u001B[0;34m(data, sample_size)\u001B[0m\n\u001B[1;32m     21\u001B[0m sample_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(full_data) \u001B[38;5;241m*\u001B[39m sample_size)\n\u001B[1;32m     22\u001B[0m sampled_data \u001B[38;5;241m=\u001B[39m random\u001B[38;5;241m.\u001B[39msample(full_data, sample_size)\n\u001B[0;32m---> 23\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_from_df\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataFrame\u001B[49m\u001B[43m(\u001B[49m\u001B[43msampled_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mitem\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrating\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtimestamp\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreader\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/surprise/dataset.py:167\u001B[0m, in \u001B[0;36mDataset.load_from_df\u001B[0;34m(cls, df, reader)\u001B[0m\n\u001B[1;32m    150\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_from_df\u001B[39m(\u001B[38;5;28mcls\u001B[39m, df, reader):\n\u001B[1;32m    152\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Load a dataset from a pandas dataframe.\u001B[39;00m\n\u001B[1;32m    153\u001B[0m \n\u001B[1;32m    154\u001B[0m \u001B[38;5;124;03m    Use this if you want to use a custom dataset that is stored in a pandas\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;124;03m            specified.\u001B[39;00m\n\u001B[1;32m    165\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 167\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDatasetAutoFolds\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdf\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/surprise/dataset.py:262\u001B[0m, in \u001B[0;36mDatasetAutoFolds.__init__\u001B[0;34m(self, ratings_file, reader, df)\u001B[0m\n\u001B[1;32m    260\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m df \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdf \u001B[38;5;241m=\u001B[39m df\n\u001B[0;32m--> 262\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw_ratings \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    263\u001B[0m         (uid, iid, \u001B[38;5;28mfloat\u001B[39m(r), \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    264\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m (uid, iid, r) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdf\u001B[38;5;241m.\u001B[39mitertuples(index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    265\u001B[0m     ]\n\u001B[1;32m    266\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    267\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMust specify ratings file or dataframe.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/surprise/dataset.py:264\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    260\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m df \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdf \u001B[38;5;241m=\u001B[39m df\n\u001B[1;32m    262\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw_ratings \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    263\u001B[0m         (uid, iid, \u001B[38;5;28mfloat\u001B[39m(r), \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m--> 264\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m (uid, iid, r) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdf\u001B[38;5;241m.\u001B[39mitertuples(index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    265\u001B[0m     ]\n\u001B[1;32m    266\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    267\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMust specify ratings file or dataframe.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "reader = Reader(line_format='user item rating', sep='::')\n",
    "# 从文件加载数据\n",
    "# rating_file = os.path.join('file', 'output.dat')\n",
    "rating_file = '../file/output3.dat'\n",
    "\n",
    "# 读取数据\n",
    "data = Dataset.load_from_file(rating_file, reader=reader)\n",
    "\n",
    "\n",
    "# 数据采样：随机抽取一定比例的数据（例如，10%）\n",
    "def sample_data(data, sample_size=0.1):\n",
    "    full_data = data.raw_ratings\n",
    "    sample_size = int(len(full_data) * sample_size)\n",
    "    sampled_data = random.sample(full_data, sample_size)\n",
    "    return Dataset.load_from_df(pd.DataFrame(sampled_data, columns=['user', 'item', 'rating', 'timestamp']), reader)\n",
    "\n",
    "\n",
    "# 增量训练\n",
    "def incremental_train(data, batch_size=1000, n_factors=40, lr_all=0.007, reg_all=0.02):\n",
    "    # 初始化模型\n",
    "    algo = SVD(n_factors=n_factors, lr_all=lr_all, reg_all=reg_all)\n",
    "\n",
    "    # 将数据分割为多个小批次\n",
    "    full_data = data.raw_ratings\n",
    "    random.shuffle(full_data)\n",
    "    batches = [full_data[i:i + batch_size] for i in range(0, len(full_data), batch_size)]\n",
    "\n",
    "    for batch in batches:\n",
    "        batch_data = Dataset.load_from_df(pd.DataFrame(batch, columns=['user', 'item', 'rating']), reader)\n",
    "        trainset = batch_data.build_full_trainset()\n",
    "        algo.fit(trainset)\n",
    "\n",
    "    return algo\n",
    "\n",
    "\n",
    "# 数据采样\n",
    "sampled_data = sample_data(data, sample_size=0.1)\n",
    "\n",
    "# 数据划分\n",
    "trainset, testset = train_test_split(sampled_data, test_size=0.25)\n",
    "\n",
    "# 增量训练模型\n",
    "algo = incremental_train(sampled_data, batch_size=1000, n_factors=40, lr_all=0.007, reg_all=0.02)\n",
    "\n",
    "# 在测试集上进行预测并评估模型\n",
    "predictions = algo.test(testset)\n",
    "accuracy.rmse(predictions)\n",
    "\n",
    "\n",
    "# 推荐函数\n",
    "def get_top_n_recommendations(predictions, n=10):\n",
    "    \"\"\"为每个用户推荐前N个产品\"\"\"\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "    return top_n\n",
    "\n",
    "\n",
    "# 在全训练集上进行预测\n",
    "train_predictions = algo.test(trainset.build_testset())"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 获取推荐结果\n",
    "user_id = '123'\n",
    "top_n = get_top_n_recommendations(train_predictions, n=10)\n",
    "\n",
    "# 打印推荐结果\n",
    "for uid, user_ratings in top_n.items():\n",
    "    if uid == user_id:\n",
    "        print(f\"User ——> {uid}:\")\n",
    "        for (iid, est) in user_ratings:\n",
    "            print(f\"  推荐 {iid}: 预测评分 {est}\")\n"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": 0
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
