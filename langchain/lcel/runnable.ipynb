{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 管道里使用的\n",
    "## RunnableLambda：把方法转成Runnable方法,对数据的处理\n",
    "## RunnableParallel：生成Runnable字典，可以添加额外参数\n",
    "## RunnablePassthrough：传递参数\n",
    "### RunnablePassthrough.assign，传递参数输出的同时，可以添加额外参数"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86aef879b365a811"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72b55e434130a24a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T06:53:44.543757Z",
     "start_time": "2024-07-02T06:53:44.537805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'origin': 1, 'modified': 2}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import (\n",
    "    RunnableLambda,\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "\n",
    "# RunnableParallel,生成Runnable字典（可以添加字段）\n",
    "runnable = RunnableParallel(\n",
    "    origin=RunnablePassthrough(),\n",
    "    modified=lambda x: x + 1\n",
    ")\n",
    "\n",
    "runnable.invoke(1)  # {'origin': 1, 'modified': 2}"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'original': '123456', 'parsed': '654321'}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fake_llm(prompt: str) -> str:  # Fake LLM for the example\n",
    "    return \"123456\"\n",
    "\n",
    "\n",
    "# 'parsed': lambda text: text[::-1] 它定义了一个匿名函数（lambda函数），用于字符串的反转操作。\n",
    "# [::-1]意味着从开始到结束，步长为-1，即反向遍历字符串，从而实现字符串的反转。\n",
    "# text的值其实就是original的值\n",
    "chain = RunnableLambda(fake_llm) | {\n",
    "    'original': RunnablePassthrough(),  # Original LLM output\n",
    "    'parsed': lambda text: text[::-1]  # Parsing logic\n",
    "}\n",
    "\n",
    "chain.invoke('hello')  # {'original': 'completion', 'parsed': 'noitelpmoc'}"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-02T06:54:34.606685Z",
     "start_time": "2024-07-02T06:54:34.595258Z"
    }
   },
   "id": "initial_id",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'llm1': '123456', 'llm2': '123456', 'total_chars': 12}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "def fake_llm(prompt: str) -> str:  # Fake LLM for the example\n",
    "    return \"123456\"\n",
    "\n",
    "\n",
    "# RunnablePassthrough.assign: 在某些情况下，在传递输入的同时向输出添加一些键可能会很有用。在这种情况下，您可以使用“assign”方法：\n",
    "runnable = {\n",
    "               'llm1': fake_llm,\n",
    "               'llm2': fake_llm,\n",
    "           } | RunnablePassthrough.assign(\n",
    "    total_chars=lambda inputs: len(inputs['llm1'] + inputs['llm2'])\n",
    ")\n",
    "\n",
    "runnable.invoke('hello')\n",
    "# {'llm1': 'completion', 'llm2': 'completion', 'total_chars': 20}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T06:58:26.765178Z",
     "start_time": "2024-07-02T06:58:26.728558Z"
    }
   },
   "id": "2f3a5e825219ac9b",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'llm1': '123456', 'llm2': '123456', 'total_chars': 12}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable = {\n",
    "               'llm1': fake_llm,\n",
    "               'llm2': fake_llm,\n",
    "           } | RunnablePassthrough.assign(\n",
    "    total_chars=lambda inputs: len(inputs['llm1'] + inputs['llm2'])\n",
    ")\n",
    "\n",
    "runnable.invoke('hello')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T07:04:40.751754Z",
     "start_time": "2024-07-02T07:04:40.711961Z"
    }
   },
   "id": "de9c434d901e0e0d",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()\n",
    "joke_chain = (\n",
    "        ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
    "        | model\n",
    ")\n",
    "poem_chain = (\n",
    "        ChatPromptTemplate.from_template(\"write a 2-line poem about {topic}\")\n",
    "        | model\n",
    ")\n",
    "\n",
    "runnable = RunnableParallel(joke=joke_chain, poem=poem_chain)\n",
    "\n",
    "# {key: \"\" for ...}: 这是字典推导式的结构。对于runnable.output_schema()中的每一个键，它都会创建一个新的键值对，\n",
    "# 其中键是迭代中得到的键，值则是空字符串\"\"。\n",
    "output = {key: \"\" for key, _ in runnable.output_schema()}\n",
    "for chunk in runnable.stream({\"topic\": \"bear\"}):\n",
    "    for key in chunk:\n",
    "        output[key] = output[key] + chunk[key].content\n",
    "    print(output)  # noqa: T201"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73a45b04cde24d4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'input': 5, 'add_step': {'added': 15}}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a RunnableAssign\n",
    "from typing import Dict\n",
    "from langchain_core.runnables.passthrough import (\n",
    "    RunnableAssign,\n",
    "    RunnableParallel,\n",
    ")\n",
    "from langchain_core.runnables.base import RunnableLambda\n",
    "\n",
    "\n",
    "def add_ten(x: Dict[str, int]) -> Dict[str, int]:\n",
    "    return {\"added\": x[\"input\"] + 10}\n",
    "\n",
    "\n",
    "mapper = RunnableParallel(\n",
    "    {\"add_step\": RunnableLambda(add_ten), }\n",
    ")\n",
    "\n",
    "runnable_assign = RunnableAssign(mapper)\n",
    "\n",
    "# Synchronous example\n",
    "runnable_assign.invoke({\"input\": 5})\n",
    "# returns {'input': 5, 'add_step': {'added': 15}}\n",
    "\n",
    "# Asynchronous example\n",
    "# await runnable_assign.ainvoke({\"input\": 5})\n",
    "# returns {'input': 5, 'add_step': {'added': 15}}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T08:29:26.825148Z",
     "start_time": "2024-07-02T08:29:26.812437Z"
    }
   },
   "id": "606185039c229b61",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# _inputs = RunnableParallel(\n",
    "#   standalone_question=RunnablePassthrough.assign(\n",
    "#     chat_history=lambda x: _format_chat_history(x[\"chat_history\"])\n",
    "#   )\n",
    "#                       | CONDENSE_QUESTION_PROMPT\n",
    "#                       | llm\n",
    "#                       | StrOutputParser(),\n",
    "# )\n",
    "# \n",
    "# _context = {\n",
    "#   \"context\": itemgetter(\"standalone_question\") | retriever | _combine_documents,\n",
    "#   \"question\": lambda x: x[\"standalone_question\"],\n",
    "# }\n",
    "# \n",
    "# chain = _inputs | _context | LLM_CONTEXT_PROMPT | llm | StrOutputParser()\n",
    "# \n",
    "# chain = chain.with_types(input_type=ChainInput)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e61a41ed6fee8ced"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
