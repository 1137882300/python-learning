{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-11T07:08:26.768200Z",
     "start_time": "2024-06-11T07:08:22.870095Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Collecting langchain-huggingface\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/39/ce/ad7f50a6289cf562747df9a966b4d60a848571db2e57ad8d00dca2478096/langchain_huggingface-0.0.3-py3-none-any.whl (17 kB)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /Users/pangmengting/venv/lib/python3.10/site-packages (from langchain-huggingface) (0.23.3)\r\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.52 in /Users/pangmengting/venv/lib/python3.10/site-packages (from langchain-huggingface) (0.2.3)\r\n",
      "Collecting sentence-transformers>=2.6.0 (from langchain-huggingface)\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/58/4b/922436953394e1bfda05e4bf1fe0e80f609770f256c59a9df7a9254f3e0d/sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m227.1/227.1 kB\u001B[0m \u001B[31m461.2 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: tokenizers>=0.19.1 in /Users/pangmengting/venv/lib/python3.10/site-packages (from langchain-huggingface) (0.19.1)\r\n",
      "Requirement already satisfied: transformers>=4.39.0 in /Users/pangmengting/venv/lib/python3.10/site-packages (from langchain-huggingface) (4.41.2)\r\n",
      "Requirement already satisfied: filelock in /Users/pangmengting/venv/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.12.2)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/pangmengting/venv/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2023.6.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/pangmengting/venv/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (23.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/pangmengting/venv/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.1)\r\n",
      "Requirement already satisfied: requests in /Users/pangmengting/venv/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/pangmengting/venv/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.65.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/pangmengting/venv/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.10.0)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/pangmengting/venv/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface) (1.33)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.65 in /Users/pangmengting/venv/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface) (0.1.67)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/pangmengting/venv/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface) (2.6.4)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/pangmengting/venv/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface) (8.2.3)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/pangmengting/venv/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.0.1)\r\n",
      "Requirement already satisfied: numpy in /Users/pangmengting/venv/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.25.1)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/pangmengting/venv/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\r\n",
      "Requirement already satisfied: scipy in /Users/pangmengting/venv/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.11.1)\r\n",
      "Requirement already satisfied: Pillow in /Users/pangmengting/venv/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (10.0.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/pangmengting/venv/lib/python3.10/site-packages (from transformers>=4.39.0->langchain-huggingface) (2023.6.3)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/pangmengting/venv/lib/python3.10/site-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.2)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/pangmengting/venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.52->langchain-huggingface) (2.4)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/pangmengting/venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.65->langchain-core<0.3,>=0.1.52->langchain-huggingface) (3.9.15)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/pangmengting/venv/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-huggingface) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/pangmengting/venv/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-huggingface) (2.16.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pangmengting/venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.2.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pangmengting/venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pangmengting/venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.2.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pangmengting/venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2024.6.2)\r\n",
      "Requirement already satisfied: sympy in /Users/pangmengting/venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/pangmengting/venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/pangmengting/venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/pangmengting/venv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/pangmengting/venv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.2.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/pangmengting/venv/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/pangmengting/venv/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\r\n",
      "Installing collected packages: sentence-transformers, langchain-huggingface\r\n",
      "  Attempting uninstall: sentence-transformers\r\n",
      "    Found existing installation: sentence-transformers 2.5.1\r\n",
      "    Uninstalling sentence-transformers-2.5.1:\r\n",
      "      Successfully uninstalled sentence-transformers-2.5.1\r\n",
      "Successfully installed langchain-huggingface-0.0.3 sentence-transformers-3.0.1\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade --quiet  tiktoken supabase unstructured\n",
    "# !pip install -i https://pypi.tuna.tsinghua.edu.cn/simple --upgrade python-docx\n",
    "# !pip install pillow-heif\n",
    "# !pip install opencv-python\n",
    "# !pip install -U langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.vectorstores import SupabaseVectorStore\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from supabase.client import Client, create_client\n",
    "\n",
    "os.environ[\"SUPABASE_URL\"] = 'https://infrxrfaftyrxvkwvncf.supabase.co'\n",
    "os.environ[\n",
    "    \"SUPABASE_SERVICE_KEY\"] = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImluZnJ4cmZhZnR5cnh2a3d2bmNmIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MTc5MTMwOTMsImV4cCI6MjAzMzQ4OTA5M30.4XcckGc0Uk-jj5j1aNbN2HnuXEi6Z4bjUrsAEhApXeM'\n",
    "\n",
    "supabase_url = os.environ.get(\"SUPABASE_URL\")\n",
    "supabase_key = os.environ.get(\"SUPABASE_SERVICE_KEY\")\n",
    "supabase: Client = create_client(supabase_url, supabase_key)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T10:50:07.944333Z",
     "start_time": "2024-06-11T10:50:07.934723Z"
    }
   },
   "id": "5af41b67aa5d500e",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 15:14:11,412:INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "2024-06-11 15:14:15,678:INFO - Use pytorch device_name: mps\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 向量化的初始化\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "# sentence-transformers/all-MiniLM-L6-v2\n",
    "# embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T07:14:15.987177Z",
     "start_time": "2024-06-11T07:14:11.397014Z"
    }
   },
   "id": "f72a45333c55e7fc",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://infrxrfaftyrxvkwvncf.supabase.co eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImluZnJ4cmZhZnR5cnh2a3d2bmNmIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MTc5MTMwOTMsImV4cCI6MjAzMzQ4OTA5M30.4XcckGc0Uk-jj5j1aNbN2HnuXEi6Z4bjUrsAEhApXeM\n"
     ]
    }
   ],
   "source": [
    "print(supabase_url, supabase_key)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T07:13:03.582989Z",
     "start_time": "2024-06-11T07:13:03.579034Z"
    }
   },
   "id": "2e8a70d1678a110b",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredURLLoader\n",
    "\n",
    "urls = [\"https://supabase.com/blog/openai-embeddings-postgres-vector\"]\n",
    "\n",
    "loader = UnstructuredURLLoader(urls=urls)\n",
    "docs = loader.load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T07:05:09.880495Z",
     "start_time": "2024-06-11T07:04:52.435179Z"
    }
   },
   "id": "f9e095c2eb96df0d",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 6\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_text_splitters\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RecursiveCharacterTextSplitter\n\u001B[1;32m      3\u001B[0m text_splitter \u001B[38;5;241m=\u001B[39m RecursiveCharacterTextSplitter(\n\u001B[1;32m      4\u001B[0m     chunk_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m, chunk_overlap\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m200\u001B[39m, add_start_index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m      5\u001B[0m )\n\u001B[0;32m----> 6\u001B[0m splits \u001B[38;5;241m=\u001B[39m text_splitter\u001B[38;5;241m.\u001B[39msplit_documents(\u001B[43mdocs\u001B[49m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'docs' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T10:30:57.954496Z",
     "start_time": "2024-06-11T10:30:57.900052Z"
    }
   },
   "id": "fe634e6be7a4c3cd",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "22"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T07:05:29.728935Z",
     "start_time": "2024-06-11T07:05:29.722467Z"
    }
   },
   "id": "6592398cd96b7bdb",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[Document(page_content=\"Back\\n\\nBlog\\n\\nStoring OpenAI embeddings in Postgres with pgvector\\n\\n2023-02-06\\n\\n15 minute read\\n\\nGreg RichardsonEngineering\\n\\nA new PostgreSQL extension is now available in Supabase: pgvector, an open-source vector similarity search.\\n\\nThe exponential progress of AI functionality over the past year has inspired many new real world applications. One specific challenge has been the ability to store and query embeddings at scale.\\nIn this post we'll explain what embeddings are, why we might want to use them, and how we can store and query them in PostgreSQL using pgvector.\\n\\n🆕 Supabase has now released an open source toolkit for developing AI applications using Postgres and pgvector. Learn more in the AI & Vectors docs.\\n\\nWhat are embeddings?#\\n\\nEmbeddings capture the “relatedness” of text, images, video, or other types of information. This relatedness is most commonly used for:\\n\\nSearch: how similar is a search term to a body of text?\\n\\nRecommendations: how similar are two products?\", metadata={'source': 'https://supabase.com/blog/openai-embeddings-postgres-vector', 'start_index': 0}),\n Document(page_content=\"Search: how similar is a search term to a body of text?\\n\\nRecommendations: how similar are two products?\\n\\nClassifications: how do we categorize a body of text?\\n\\nClustering: how do we identify trends?\\n\\nLet's explore an example of text embeddings. Say we have three phrases:\\n\\n“The cat chases the mouse”\\n\\n“The kitten hunts rodents”\\n\\n“I like ham sandwiches”\\n\\nYour job is to group phrases with similar meaning. If you are a human, this should be obvious. Phrases 1 and 2 are almost identical, while phrase 3 has a completely different meaning.\\n\\nAlthough phrases 1 and 2 are similar, they share no common vocabulary (besides “the”). Yet their meanings are nearly identical. How can we teach a computer that these are the same?\\n\\nHuman language#\", metadata={'source': 'https://supabase.com/blog/openai-embeddings-postgres-vector', 'start_index': 880}),\n Document(page_content='Although phrases 1 and 2 are similar, they share no common vocabulary (besides “the”). Yet their meanings are nearly identical. How can we teach a computer that these are the same?\\n\\nHuman language#\\n\\nHumans use words and symbols to communicate language. But words in isolation are mostly meaningless - we need to draw from shared knowledge & experience in order to make sense of them. The phrase “You should Google it” only makes sense if you know that Google is a search engine and that people have been using it as a verb.\\n\\nIn the same way, we need to train a neural network model to understand human language. An effective model should be trained on millions of different examples to understand what each word, phrase, sentence, or paragraph could mean in different contexts.\\n\\nSo how does this relate to embeddings?\\n\\nHow do embeddings work?#', metadata={'source': 'https://supabase.com/blog/openai-embeddings-postgres-vector', 'start_index': 1419}),\n Document(page_content=\"So how does this relate to embeddings?\\n\\nHow do embeddings work?#\\n\\nEmbeddings compress discrete information (words & symbols) into distributed continuous-valued data (vectors). If we took our phrases from before and plot them on a chart, it might look something like this:\\n\\nPhrases 1 and 2 would be plotted close to each other, since their meanings are similar. We would expect phrase 3 to live somewhere far away since it isn't related. If we had a fourth phrase, “Sally ate Swiss cheese”, this might exist somewhere between phrase 3 (cheese can go on sandwiches) and phrase 1 (mice like Swiss cheese).\\n\\nIn this example we only have 2 dimensions: the X and Y axis. In reality, we would need many more dimensions to effectively capture the complexities of human language.\\n\\nOpenAI embeddings#\", metadata={'source': 'https://supabase.com/blog/openai-embeddings-postgres-vector', 'start_index': 2198}),\n Document(page_content=\"In this example we only have 2 dimensions: the X and Y axis. In reality, we would need many more dimensions to effectively capture the complexities of human language.\\n\\nOpenAI embeddings#\\n\\nOpenAI offers an API to generate embeddings for a string of text using its language model. You feed it any text information (blog articles, documentation, your company's knowledge base), and it will output a vector of floating point numbers that represents the “meaning” of that text.\\n\\nCompared to our 2-dimensional example above, their latest embedding model text-embedding-ada-002 will output 1536 dimensions.\\n\\nWhy is this useful? Once we have generated embeddings on multiple texts, it is trivial to calculate how similar they are using vector math operations like cosine distance. A perfect use case for this is search. Your process might look something like this:\\n\\nPre-process your knowledge base and generate embeddings for each page\\n\\nStore your embeddings to be referenced later (more on this)\", metadata={'source': 'https://supabase.com/blog/openai-embeddings-postgres-vector', 'start_index': 2802}),\n Document(page_content=\"Pre-process your knowledge base and generate embeddings for each page\\n\\nStore your embeddings to be referenced later (more on this)\\n\\nBuild a search page that prompts your user for input\\n\\nTake user's input, generate a one-time embedding, then perform a similarity search against your pre-processed embeddings.\\n\\nReturn the most similar pages to the user\\n\\nEmbeddings in practice#\\n\\nAt a small scale, you could store your embeddings in a CSV file, load them into Python, and use a library like numPy to calculate similarity between them using something like cosine distance or dot product. OpenAI has a cookbook example that does just that. Unfortunately this likely won't scale well:\\n\\nWhat if I need to store and search over a large number of documents and embeddings (more than can fit in memory)?\\n\\nWhat if I want to create/update/delete embeddings dynamically?\\n\\nWhat if I'm not using Python?\\n\\nUsing PostgreSQL#\", metadata={'source': 'https://supabase.com/blog/openai-embeddings-postgres-vector', 'start_index': 3660}),\n Document(page_content=\"What if I want to create/update/delete embeddings dynamically?\\n\\nWhat if I'm not using Python?\\n\\nUsing PostgreSQL#\\n\\nEnter pgvector, an extension for PostgreSQL that allows you to both store and query vector embeddings within your database. Let's try it out.\\n\\nFirst we'll enable the Vector extension. In Supabase, this can be done from the web portal through Database → Extensions. You can also do this in SQL by running:\\n\\n_10\\n\\ncreate extension vector;\\n\\nNext let's create a table to store our documents and their embeddings:\\n\\n_10\\n\\ncreate table documents (\\n\\n_10\\n\\nid bigserial primary key,\\n\\n_10\\n\\ncontent text,\\n\\n_10\\n\\nembedding vector(1536)\\n\\n_10\\n\\n);\\n\\npgvector introduces a new data type called vector. In the code above, we create a column named embedding with the vector data type. The size of the vector defines how many dimensions the vector holds. OpenAI's text-embedding-ada-002 model outputs 1536 dimensions, so we will use that for our vector size.\", metadata={'source': 'https://supabase.com/blog/openai-embeddings-postgres-vector', 'start_index': 4455}),\n Document(page_content=\"We also create a text column named content to store the original document text that produced this embedding. Depending on your use case, you might just store a reference (URL or foreign key) to a document here instead.\\n\\nSoon we're going to need to perform a similarity search over these embeddings. Let's create a function to do that:\\n\\n_21\\n\\ncreate or replace function match_documents (\\n\\n_21\\n\\nquery_embedding vector(1536),\\n\\n_21\\n\\nmatch_threshold float,\\n\\n_21\\n\\nmatch_count int\\n\\n_21\\n\\n_21\\n\\nreturns table (\\n\\n_21\\n\\nid bigint,\\n\\n_21\\n\\ncontent text,\\n\\n_21\\n\\nsimilarity float\\n\\n_21\\n\\n_21\\n\\nlanguage sql stable\\n\\n_21\\n\\nas $$\\n\\n_21\\n\\nselect\\n\\n_21\\n\\ndocuments.id,\\n\\n_21\\n\\ndocuments.content,\\n\\n_21\\n\\n1 - (documents.embedding <=> query_embedding) as similarity\\n\\n_21\\n\\nfrom documents\\n\\n_21\\n\\nwhere documents.embedding <=> query_embedding < 1 - match_threshold\\n\\n_21\\n\\norder by documents.embedding <=> query_embedding\\n\\n_21\\n\\nlimit match_count;\\n\\n_21\\n\\n$$;\\n\\npgvector introduces 3 new operators that can be used to calculate similarity:\", metadata={'source': 'https://supabase.com/blog/openai-embeddings-postgres-vector', 'start_index': 5405}),\n Document(page_content=\"_21\\n\\norder by documents.embedding <=> query_embedding\\n\\n_21\\n\\nlimit match_count;\\n\\n_21\\n\\n$$;\\n\\npgvector introduces 3 new operators that can be used to calculate similarity:\\n\\nOperator Description <-> Euclidean distance <#> negative inner product <=> cosine distance\\n\\nOpenAI recommends cosine similarity on their embeddings, so we will use that here.\\n\\nNow we can call match_documents(), pass in our embedding, similarity threshold, and match count, and we'll get a list of all documents that match. And since this is all managed by Postgres, our application code becomes very simple.\\n\\nIndexing#\\n\\nOnce your table starts to grow with embeddings, you will likely want to add an index to speed up queries. Vector indexes are particularly important when you're ordering results because vectors are not grouped by similarity, so finding the closest by sequential scan is a resource-intensive operation.\", metadata={'source': 'https://supabase.com/blog/openai-embeddings-postgres-vector', 'start_index': 6228}),\n Document(page_content=\"Each distance operator requires a different type of index. We expect to order by cosine distance, so we need vector_cosine_ops index. A good starting number of lists is 4 * sqrt(table_rows):\\n\\n_10\\n\\ncreate index on documents using ivfflat (embedding vector_cosine_ops)\\n\\n_10\\n\\nwith\\n\\n_10\\n\\n(lists = 100);\\n\\nYou can read more about indexing on pgvector's GitHub page here.\\n\\nGenerating embeddings#\\n\\nLet's use JavaScript to generate embeddings and store them in Postgres:\\n\\n_29\\n\\nimport { createClient } from '@supabase/supabase-js'\\n\\n_29\\n\\nimport { Configuration, OpenAIApi } from 'openai'\\n\\n_29\\n\\nimport { supabaseClient } from './lib/supabase'\\n\\n_29\\n\\n_29\\n\\nasync function generateEmbeddings() {\\n\\n_29\\n\\nconst configuration = new Configuration({ apiKey: '<YOUR_OPENAI_API_KEY>' })\\n\\n_29\\n\\nconst openAi = new OpenAIApi(configuration)\\n\\n_29\\n\\n_29\\n\\nconst documents = await getDocuments() // Your custom function to load docs\\n\\n_29\\n\\n_29\\n\\n// Assuming each document is a string\\n\\n_29\\n\\nfor (const document of documents) {\\n\\n_29\", metadata={'source': 'https://supabase.com/blog/openai-embeddings-postgres-vector', 'start_index': 7119}),\n Document(page_content=\"_29\\n\\n_29\\n\\nconst documents = await getDocuments() // Your custom function to load docs\\n\\n_29\\n\\n_29\\n\\n// Assuming each document is a string\\n\\n_29\\n\\nfor (const document of documents) {\\n\\n_29\\n\\n// OpenAI recommends replacing newlines with spaces for best results\\n\\n_29\\n\\nconst input = document.replace(/\\\\n/g, ' ')\\n\\n_29\\n\\n_29\\n\\nconst embeddingResponse = await openai.createEmbedding({\\n\\n_29\\n\\nmodel: 'text-embedding-ada-002',\\n\\n_29\\n\\ninput,\\n\\n_29\\n\\n})\\n\\n_29\\n\\n_29\\n\\nconst [{ embedding }] = embeddingResponse.data.data\\n\\n_29\\n\\n_29\\n\\n// In production we should handle possible errors\\n\\n_29\\n\\nawait supabaseClient.from('documents').insert({\\n\\n_29\\n\\ncontent: document,\\n\\n_29\\n\\nembedding,\\n\\n_29\\n\\n})\\n\\n_29\\n\\n_29\\n\\nBuilding a simple search function#\\n\\nFinally, let's create an Edge Function to perform our similarity search:\\n\\n_45\\n\\nimport { serve } from 'https://deno.land/[email\\xa0protected]/http/server.ts'\\n\\n_45\\n\\nimport 'https://deno.land/x/[email\\xa0protected]/mod.ts'\\n\\n_45\", metadata={'source': 'https://supabase.com/blog/openai-embeddings-postgres-vector', 'start_index': 7933}),\n Document(page_content=\"_45\\n\\nimport { serve } from 'https://deno.land/[email\\xa0protected]/http/server.ts'\\n\\n_45\\n\\nimport 'https://deno.land/x/[email\\xa0protected]/mod.ts'\\n\\n_45\\n\\nimport { createClient } from 'https://esm.sh/@supabase/[email\\xa0protected]'\\n\\n_45\\n\\nimport { Configuration, OpenAIApi } from 'https://esm.sh/[email\\xa0protected]'\\n\\n_45\\n\\nimport { supabaseClient } from './lib/supabase'\\n\\n_45\\n\\n_45\\n\\nexport const corsHeaders = {\\n\\n_45\\n\\n'Access-Control-Allow-Origin': '*',\\n\\n_45\\n\\n'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',\\n\\n_45\\n\\n_45\\n\\n_45\\n\\nserve(async (req) => {\\n\\n_45\\n\\n// Handle CORS\\n\\n_45\\n\\nif (req.method === 'OPTIONS') {\\n\\n_45\\n\\nreturn new Response('ok', { headers: corsHeaders })\\n\\n_45\\n\\n_45\\n\\n_45\\n\\n// Search query is passed in request payload\\n\\n_45\\n\\nconst { query } = await req.json()\\n\\n_45\\n\\n_45\\n\\n// OpenAI recommends replacing newlines with spaces for best results\\n\\n_45\\n\\nconst input = query.replace(/\\\\n/g, ' ')\\n\\n_45\\n\\n_45\", metadata={'source': 'https://supabase.com/blog/openai-embeddings-postgres-vector', 'start_index': 8713}),\n Document(page_content=\"_45\\n\\nconst { query } = await req.json()\\n\\n_45\\n\\n_45\\n\\n// OpenAI recommends replacing newlines with spaces for best results\\n\\n_45\\n\\nconst input = query.replace(/\\\\n/g, ' ')\\n\\n_45\\n\\n_45\\n\\nconst configuration = new Configuration({ apiKey: '<YOUR_OPENAI_API_KEY>' })\\n\\n_45\\n\\nconst openai = new OpenAIApi(configuration)\\n\\n_45\\n\\n_45\\n\\n// Generate a one-time embedding for the query itself\\n\\n_45\\n\\nconst embeddingResponse = await openai.createEmbedding({\\n\\n_45\\n\\nmodel: 'text-embedding-ada-002',\\n\\n_45\\n\\ninput,\\n\\n_45\\n\\n})\\n\\n_45\\n\\n_45\\n\\nconst [{ embedding }] = embeddingResponse.data.data\\n\\n_45\\n\\n_45\\n\\n// In production we should handle possible errors\\n\\n_45\\n\\nconst { data: documents } = await supabaseClient.rpc('match_documents', {\\n\\n_45\\n\\nquery_embedding: embedding,\\n\\n_45\\n\\nmatch_threshold: 0.78, // Choose an appropriate threshold for your data\\n\\n_45\\n\\nmatch_count: 10, // Choose the number of matches\\n\\n_45\\n\\n})\\n\\n_45\\n\\n_45\\n\\nreturn new Response(JSON.stringify(documents), {\\n\\n_45\", metadata={'source': 'https://supabase.com/blog/openai-embeddings-postgres-vector', 'start_index': 9461}),\n Document(page_content=\"_45\\n\\nmatch_count: 10, // Choose the number of matches\\n\\n_45\\n\\n})\\n\\n_45\\n\\n_45\\n\\nreturn new Response(JSON.stringify(documents), {\\n\\n_45\\n\\nheaders: { ...corsHeaders, 'Content-Type': 'application/json' },\\n\\n_45\\n\\n})\\n\\n_45\\n\\n})\\n\\nBuilding a smarter search function#\\n\\nChatGPT doesn't just return existing documents. It's able to assimilate a variety of information into a single, cohesive answer. To do this, we need to provide GPT with some relevant documents, and a prompt that it can use to formulate this answer.\\n\\nOne of the biggest challenges of OpenAI's text-davinci-003 completion model is the 4000 token limit. You must fit both your prompt and the resulting completion within the 4000 tokens. This makes it challenging if you wanted to prompt GPT-3 to answer questions about your own custom knowledge base that would never fit in a single prompt.\\n\\nEmbeddings can help solve this by splitting your prompts into a two-phased process:\", metadata={'source': 'https://supabase.com/blog/openai-embeddings-postgres-vector', 'start_index': 10271}),\n Document(page_content=\"Embeddings can help solve this by splitting your prompts into a two-phased process:\\n\\nQuery your embedding database for the most relevant documents related to the question\\n\\nInject these documents as context for GPT-3 to reference in its answer\\n\\nHere's another Edge Function that expands upon the simple example above:\\n\\n_100\\n\\nimport { serve } from 'https://deno.land/[email\\xa0protected]/http/server.ts'\\n\\n_100\\n\\nimport 'https://deno.land/x/[email\\xa0protected]/mod.ts'\\n\\n_100\\n\\nimport { createClient } from 'https://esm.sh/@supabase/[email\\xa0protected]'\\n\\n_100\\n\\nimport GPT3Tokenizer from 'https://esm.sh/[email\\xa0protected]'\\n\\n_100\\n\\nimport { Configuration, OpenAIApi } from 'https://esm.sh/[email\\xa0protected]'\\n\\n_100\\n\\nimport { oneLine, stripIndent } from 'https://esm.sh/[email\\xa0protected]'\\n\\n_100\\n\\nimport { supabaseClient } from './lib/supabase'\\n\\n_100\\n\\n_100\\n\\nexport const corsHeaders = {\\n\\n_100\\n\\n'Access-Control-Allow-Origin': '*',\\n\\n_100\", metadata={'source': 'https://supabase.com/blog/openai-embeddings-postgres-vector', 'start_index': 11110}),\n Document(page_content=\"_100\\n\\nimport { supabaseClient } from './lib/supabase'\\n\\n_100\\n\\n_100\\n\\nexport const corsHeaders = {\\n\\n_100\\n\\n'Access-Control-Allow-Origin': '*',\\n\\n_100\\n\\n'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',\\n\\n_100\\n\\n_100\\n\\n_100\\n\\nserve(async (req) => {\\n\\n_100\\n\\n// Handle CORS\\n\\n_100\\n\\nif (req.method === 'OPTIONS') {\\n\\n_100\\n\\nreturn new Response('ok', { headers: corsHeaders })\\n\\n_100\\n\\n_100\\n\\n_100\\n\\n// Search query is passed in request payload\\n\\n_100\\n\\nconst { query } = await req.json()\\n\\n_100\\n\\n_100\\n\\n// OpenAI recommends replacing newlines with spaces for best results\\n\\n_100\\n\\nconst input = query.replace(/\\\\n/g, ' ')\\n\\n_100\\n\\n_100\\n\\nconst configuration = new Configuration({ apiKey: '<YOUR_OPENAI_API_KEY>' })\\n\\n_100\\n\\nconst openai = new OpenAIApi(configuration)\\n\\n_100\\n\\n_100\\n\\n// Generate a one-time embedding for the query itself\\n\\n_100\\n\\nconst embeddingResponse = await openai.createEmbedding({\\n\\n_100\\n\\nmodel: 'text-embedding-ada-002',\\n\\n_100\\n\\ninput,\\n\\n_100\\n\\n})\\n\\n_100\\n\\n_100\", metadata={'source': 'https://supabase.com/blog/openai-embeddings-postgres-vector', 'start_index': 11882}),\n Document(page_content=\"// Generate a one-time embedding for the query itself\\n\\n_100\\n\\nconst embeddingResponse = await openai.createEmbedding({\\n\\n_100\\n\\nmodel: 'text-embedding-ada-002',\\n\\n_100\\n\\ninput,\\n\\n_100\\n\\n})\\n\\n_100\\n\\n_100\\n\\nconst [{ embedding }] = embeddingResponse.data.data\\n\\n_100\\n\\n_100\\n\\n// Fetching whole documents for this simple example.\\n\\n_100\\n\\n//\\n\\n_100\\n\\n// Ideally for context injection, documents are chunked into\\n\\n_100\\n\\n// smaller sections at earlier pre-processing/embedding step.\\n\\n_100\\n\\nconst { data: documents } = await supabaseClient.rpc('match_documents', {\\n\\n_100\\n\\nquery_embedding: embedding,\\n\\n_100\\n\\nmatch_threshold: 0.78, // Choose an appropriate threshold for your data\\n\\n_100\\n\\nmatch_count: 10, // Choose the number of matches\\n\\n_100\\n\\n})\\n\\n_100\\n\\n_100\\n\\nconst tokenizer = new GPT3Tokenizer({ type: 'gpt3' })\\n\\n_100\\n\\nlet tokenCount = 0\\n\\n_100\\n\\nlet contextText = ''\\n\\n_100\\n\\n_100\\n\\n// Concat matched documents\\n\\n_100\\n\\nfor (let i = 0; i < documents.length; i++) {\\n\\n_100\\n\\nconst document = documents[i]\\n\\n_100\", metadata={'source': 'https://supabase.com/blog/openai-embeddings-postgres-vector', 'start_index': 12665}),\n Document(page_content='_100\\n\\nlet tokenCount = 0\\n\\n_100\\n\\nlet contextText = \\'\\'\\n\\n_100\\n\\n_100\\n\\n// Concat matched documents\\n\\n_100\\n\\nfor (let i = 0; i < documents.length; i++) {\\n\\n_100\\n\\nconst document = documents[i]\\n\\n_100\\n\\nconst content = document.content\\n\\n_100\\n\\nconst encoded = tokenizer.encode(content)\\n\\n_100\\n\\ntokenCount += encoded.text.length\\n\\n_100\\n\\n_100\\n\\n// Limit context to max 1500 tokens (configurable)\\n\\n_100\\n\\nif (tokenCount > 1500) {\\n\\n_100\\n\\nbreak\\n\\n_100\\n\\n_100\\n\\n_100\\n\\ncontextText += `${content.trim()}\\\\n---\\\\n`\\n\\n_100\\n\\n_100\\n\\n_100\\n\\nconst prompt = stripIndent`${oneLine`\\n\\n_100\\n\\nYou are a very enthusiastic Supabase representative who loves\\n\\n_100\\n\\nto help people! Given the following sections from the Supabase\\n\\n_100\\n\\ndocumentation, answer the question using only that information,\\n\\n_100\\n\\noutputted in markdown format. If you are unsure and the answer\\n\\n_100\\n\\nis not explicitly written in the documentation, say\\n\\n_100\\n\\n\"Sorry, I don\\'t know how to help with that.\"`}\\n\\n_100\\n\\n_100\\n\\nContext sections:\\n\\n_100\\n\\n${contextText}\\n\\n_100\\n\\n_100', metadata={'source': 'https://supabase.com/blog/openai-embeddings-postgres-vector', 'start_index': 13454}),\n Document(page_content='_100\\n\\nis not explicitly written in the documentation, say\\n\\n_100\\n\\n\"Sorry, I don\\'t know how to help with that.\"`}\\n\\n_100\\n\\n_100\\n\\nContext sections:\\n\\n_100\\n\\n${contextText}\\n\\n_100\\n\\n_100\\n\\nQuestion: \"\"\"\\n\\n_100\\n\\n${query}\\n\\n_100\\n\\n\"\"\"\\n\\n_100\\n\\n_100\\n\\nAnswer as markdown (including related code snippets if available):\\n\\n_100\\n\\n_100\\n\\n_100\\n\\n// In production we should handle possible errors\\n\\n_100\\n\\nconst completionResponse = await openai.createCompletion({\\n\\n_100\\n\\nmodel: \\'text-davinci-003\\',\\n\\n_100\\n\\nprompt,\\n\\n_100\\n\\nmax_tokens: 512, // Choose the max allowed tokens in completion\\n\\n_100\\n\\ntemperature: 0, // Set to 0 for deterministic results\\n\\n_100\\n\\n})\\n\\n_100\\n\\n_100\\n\\nconst {\\n\\n_100\\n\\nid,\\n\\n_100\\n\\nchoices: [{ text }],\\n\\n_100\\n\\n} = completionResponse.data\\n\\n_100\\n\\n_100\\n\\nreturn new Response(JSON.stringify({ id, text }), {\\n\\n_100\\n\\nheaders: { ...corsHeaders, \\'Content-Type\\': \\'application/json\\' },\\n\\n_100\\n\\n})\\n\\n_100\\n\\n})\\n\\nStreaming results#', metadata={'source': 'https://supabase.com/blog/openai-embeddings-postgres-vector', 'start_index': 14275}),\n Document(page_content=\"_100\\n\\n_100\\n\\nreturn new Response(JSON.stringify({ id, text }), {\\n\\n_100\\n\\nheaders: { ...corsHeaders, 'Content-Type': 'application/json' },\\n\\n_100\\n\\n})\\n\\n_100\\n\\n})\\n\\nStreaming results#\\n\\nOpenAI API responses take longer to depending on the length of the “answer”. ChatGPT has a nice UX for this by streaming the response to the user immediately. You can see a similar effect for the Supabase docs:\\n\\nThe OpenAI API supports completion streaming with Server Side Events. Supabase Edge Functions are run Deno, which also supports Server Side Events. Check out this commit to see how we modified the Function above to build a streaming interface.\\n\\nWrap up#\\n\\nStoring embeddings in Postgres opens a world of possibilities. You can combine your search function with telemetry functions, add an user-provided feedback (thumbs up/down), and make your search feel more integrated with your products.\", metadata={'source': 'https://supabase.com/blog/openai-embeddings-postgres-vector', 'start_index': 14996}),\n Document(page_content='The pgvector extension is available on all new Supabase projects today. To try it out, launch a new Postgres database: database.new\\n\\nMore pgvector and AI resources#\\n\\nSupabase Clippy: ChatGPT for Supabase Docs\\n\\nHugging Face is now supported in Supabase\\n\\nHow to build ChatGPT Plugin from scratch with Supabase Edge Runtime\\n\\nDocs pgvector: Embeddings and vector similarity\\n\\nChoosing Compute Add-on for AI workloads\\n\\npgvector v0.5.0: Faster semantic search with HNSW indexes\\n\\nShare this article\\n\\nLast postSupabase Clippy: ChatGPT for Supabase Docs7 February 2023\\n\\nNext postSupabase Beta December 20225 January 2023\\n\\npostgres\\n\\nAI\\n\\nplanetpg\\n\\nOn this page\\n\\nWhat are embeddings?\\n\\nHuman language\\n\\nHow do embeddings work?\\n\\nOpenAI embeddings\\n\\nEmbeddings in practice\\n\\nUsing PostgreSQL\\nIndexing\\nGenerating embeddings\\nBuilding a simple search function\\nBuilding a smarter search function\\nStreaming results\\n\\nWrap up\\n\\nMore pgvector and AI resources\\n\\nShare this article\\n\\nBuild in a weekend, scale to millions', metadata={'source': 'https://supabase.com/blog/openai-embeddings-postgres-vector', 'start_index': 15877}),\n Document(page_content='Wrap up\\n\\nMore pgvector and AI resources\\n\\nShare this article\\n\\nBuild in a weekend, scale to millions\\n\\nStart your project', metadata={'source': 'https://supabase.com/blog/openai-embeddings-postgres-vector', 'start_index': 16769})]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T07:05:44.571780Z",
     "start_time": "2024-06-11T07:05:44.565448Z"
    }
   },
   "id": "a269e852be935afb",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "file_path = '../file/最后一个问题.txt'\n",
    "# loader = TextLoader(\"/Users/pangmengting/Documents/workspace/python-learning/langchain/file/最后一个问题.txt\", encoding='UTF-8')\n",
    "loader = TextLoader(file_path, encoding='UTF-8')\n",
    "data = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "splits = text_splitter.split_documents(data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T10:31:20.134971Z",
     "start_time": "2024-06-11T10:31:20.127565Z"
    }
   },
   "id": "b4027f66a4f59e63",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(splits))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T10:31:22.717321Z",
     "start_time": "2024-06-11T10:31:22.712666Z"
    }
   },
   "id": "6fdfc09d69548aef",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 18:44:05,549:INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "2024-06-11 18:44:15,980:WARNING - No sentence-transformers model found with name sentence-transformers/all-mpnet-base-v2. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d61b0899fb804b30b24bcf241eb50577"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b47fc7f3877f4a81855240bd88bc7d57"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d13a356a39194e599a48921b6f08c062"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "731eccc3876e4b8289990e983e8f8e93"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6a50da2c6a7c4b2e89c52d03bd38bfc4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0dbdad6597ab442c9b842878fdae6f3e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# sentence-transformers/all-MiniLM-L6-v2\n",
    "# sentence-transformers/all-mpnet-base-v2\n",
    "# model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embeddings_hf = HuggingFaceEmbeddings(\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T10:45:17.470834Z",
     "start_time": "2024-06-11T10:44:05.549522Z"
    }
   },
   "id": "a47df460eaa84a62",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 18:55:31,259:INFO - HTTP Request: POST https://infrxrfaftyrxvkwvncf.supabase.co/rest/v1/documents?columns=%22content%22%2C%22embedding%22%2C%22metadata%22%2C%22id%22 \"HTTP/1.1 400 Bad Request\"\n"
     ]
    },
    {
     "ename": "APIError",
     "evalue": "{'code': '22000', 'details': None, 'hint': None, 'message': 'expected 1536 dimensions, not 768'}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAPIError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 将上述文件插入数据库。嵌入将自动为每个文档生成。\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m vectorstore \u001B[38;5;241m=\u001B[39m \u001B[43mSupabaseVectorStore\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_documents\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43msplits\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43membeddings_hf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msupabase\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtable_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdocuments\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquery_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmatch_documents\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/vectorstores.py:550\u001B[0m, in \u001B[0;36mVectorStore.from_documents\u001B[0;34m(cls, documents, embedding, **kwargs)\u001B[0m\n\u001B[1;32m    548\u001B[0m texts \u001B[38;5;241m=\u001B[39m [d\u001B[38;5;241m.\u001B[39mpage_content \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m documents]\n\u001B[1;32m    549\u001B[0m metadatas \u001B[38;5;241m=\u001B[39m [d\u001B[38;5;241m.\u001B[39mmetadata \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m documents]\n\u001B[0;32m--> 550\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_texts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadatas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_community/vectorstores/supabase.py:154\u001B[0m, in \u001B[0;36mSupabaseVectorStore.from_texts\u001B[0;34m(cls, texts, embedding, metadatas, client, table_name, query_name, chunk_size, ids, **kwargs)\u001B[0m\n\u001B[1;32m    152\u001B[0m ids \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mstr\u001B[39m(uuid\u001B[38;5;241m.\u001B[39muuid4()) \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m texts]\n\u001B[1;32m    153\u001B[0m docs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_texts_to_documents(texts, metadatas)\n\u001B[0;32m--> 154\u001B[0m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_add_vectors\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtable_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdocs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunk_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(\n\u001B[1;32m    159\u001B[0m     client\u001B[38;5;241m=\u001B[39mclient,\n\u001B[1;32m    160\u001B[0m     embedding\u001B[38;5;241m=\u001B[39membedding,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    163\u001B[0m     chunk_size\u001B[38;5;241m=\u001B[39mchunk_size,\n\u001B[1;32m    164\u001B[0m )\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_community/vectorstores/supabase.py:347\u001B[0m, in \u001B[0;36mSupabaseVectorStore._add_vectors\u001B[0;34m(client, table_name, vectors, documents, ids, chunk_size, **kwargs)\u001B[0m\n\u001B[1;32m    344\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(rows), chunk_size):\n\u001B[1;32m    345\u001B[0m     chunk \u001B[38;5;241m=\u001B[39m rows[i : i \u001B[38;5;241m+\u001B[39m chunk_size]\n\u001B[0;32m--> 347\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtable_name\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupsert\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    349\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(result\u001B[38;5;241m.\u001B[39mdata) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    350\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError inserting: No rows added\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/postgrest/_sync/request_builder.py:78\u001B[0m, in \u001B[0;36mSyncQueryRequestBuilder.execute\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     76\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m APIResponse[_ReturnT]\u001B[38;5;241m.\u001B[39mfrom_http_request_response(r)\n\u001B[1;32m     77\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 78\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m APIError(r\u001B[38;5;241m.\u001B[39mjson())\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ValidationError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     80\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m APIError(r\u001B[38;5;241m.\u001B[39mjson()) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[0;31mAPIError\u001B[0m: {'code': '22000', 'details': None, 'hint': None, 'message': 'expected 1536 dimensions, not 768'}"
     ]
    }
   ],
   "source": [
    "# 将上述文件插入数据库。嵌入将自动为每个文档生成。\n",
    "vectorstore = SupabaseVectorStore.from_documents(\n",
    "    splits,\n",
    "    embeddings_hf,\n",
    "    client=supabase,\n",
    "    table_name=\"documents\",\n",
    "    query_name=\"match_documents\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T10:55:31.314497Z",
     "start_time": "2024-06-11T10:55:28.477117Z"
    }
   },
   "id": "6b570d215405c40a",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 如果你的数据库中已经有了带有嵌入的文档，只需直接实例化一个新的 SupabaseVectorStore ：\n",
    "vector_store = SupabaseVectorStore(\n",
    "    embedding=embeddings_hf,\n",
    "    client=supabase,\n",
    "    table_name=\"documents\",\n",
    "    query_name=\"match_documents\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T10:53:34.048704Z",
     "start_time": "2024-06-11T10:53:34.044906Z"
    }
   },
   "id": "4015a7875e991a55",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 18:53:58,432:INFO - HTTP Request: POST https://infrxrfaftyrxvkwvncf.supabase.co/rest/v1/rpc/match_documents?limit=6 \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "retrieved_docs = retriever.invoke(\"How to store embeddings with pgvector?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T10:53:58.449111Z",
     "start_time": "2024-06-11T10:53:56.958850Z"
    }
   },
   "id": "f7b2df1a60789cad",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mretrieved_docs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpage_content\u001B[49m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "retrieved_docs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T10:55:11.656057Z",
     "start_time": "2024-06-11T10:55:11.640438Z"
    }
   },
   "id": "338d8c37314c9122",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = '''\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "'''\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = ({\"context\": (retriever | format_docs), \"question\": RunnablePassthrough()}\n",
    "             | ChatPromptTemplate.from_template(prompt)\n",
    "             | ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "             | StrOutputParser())\n",
    "\n",
    "rag_chain.invoke(\"How to store embeddings with pgvector?\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfc739d8a938c393"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
