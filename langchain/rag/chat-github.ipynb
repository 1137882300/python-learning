{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "向量化存储github仓库代码\n",
    "进行QA问答"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e922ba6a4c734129"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 基本配置\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.embeddings.cloudflare_workersai import CloudflareWorkersAIEmbeddings\n",
    "from supabase.client import Client, create_client\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "qw_llm_openai = ChatOpenAI(\n",
    "    openai_api_base=os.getenv('DASHSCOPE_API_BASE'),\n",
    "    openai_api_key=os.getenv('DASHSCOPE_API_KEY'),\n",
    "    model_name=\"qwen2-1.5b-instruct\",\n",
    "    temperature=0.7,\n",
    "    streaming=True,\n",
    ")\n",
    "embeddings = CloudflareWorkersAIEmbeddings(\n",
    "    account_id=os.getenv('CF_ACCOUNT_ID'),\n",
    "    api_token=os.getenv('CF_API_TOKEN'),\n",
    "    model_name=\"@cf/baai/bge-large-en-v1.5\",\n",
    ")\n",
    "\n",
    "supabase_url = os.environ.get(\"SUPABASE_URL\")\n",
    "supabase_key = os.environ.get(\"SUPABASE_SERVICE_KEY\")\n",
    "\n",
    "supabase: Client = create_client(supabase_url, supabase_key)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "root_dir = '/Users/pangmengting/Documents/workspace/crab-blog-second'\n",
    "docs = []\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    for file in filenames:\n",
    "        if file == 'node_modules':\n",
    "            print(file)\n",
    "        # try:\n",
    "        #     loader = TextLoader(os.path.join(dirpath, file), encoding='utf-8')\n",
    "        #     docs.extend(loader.load_and_split())\n",
    "        # except Exception as e:\n",
    "        #     pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-04T03:30:38.987620Z",
     "start_time": "2024-07-04T03:30:38.895855Z"
    }
   },
   "id": "b5a4a85382020b02",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(docs)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df26d8c7e0fe1b1b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "splits = text_splitter.split_documents(docs)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f872e5e83ca0ca55"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(splits)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96fd1b73e2359468"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import SupabaseVectorStore\n",
    "\n",
    "vectorstore = SupabaseVectorStore.from_documents(\n",
    "    splits,\n",
    "    embeddings,\n",
    "    client=supabase,\n",
    "    table_name=\"bge_large_vector\",\n",
    "    query_name=\"bge_large_match_documents\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64b59c25a6b89773"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "retriever.search_kwargs['distance_metric'] = 'cos'\n",
    "retriever.search_kwargs['fetch_k'] = 100\n",
    "retriever.search_kwargs['maximal_marginal_relevance'] = True\n",
    "retriever.search_kwargs['k'] = 10"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b0b1e919a3c41d7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.chains.conversational_retrieval.base import ConversationalRetrievalChain\n",
    "\n",
    "# from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(qw_llm_openai, retriever=retriever)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43579e3bf6082a09"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"What does Chroma do?\",\n",
    "    \"How to use Chroma?\"\n",
    "]\n",
    "chat_history = []\n",
    "\n",
    "for question in questions:\n",
    "    result = qa({\"question\": question, \"chat_history\": chat_history})\n",
    "    chat_history.append((question, result['answer']))\n",
    "    print(f\"Question:\\n {question} \\n\")\n",
    "    print(f\"Answer:\\n {result['answer']} \\n\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cad29cdbc7675b0c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def ask(question, chat_history):\n",
    "    response = qa({\"question\": question, \"chat_history\": chat_history})\n",
    "    print(f\"Question:\\n {question}\\n\")\n",
    "    print(f\"Answer:\\n {response['answer']}\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d336db595e9f7b8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ask(\"What's the main programming language used in Chroma?\", chat_history)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bcf377e293be428"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ask('Show me the public functions of class Client', chat_history)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1f1168452c30c6e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
