{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "向量化存储github仓库代码\n",
    "进行QA问答"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e922ba6a4c734129"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-04T05:52:20.436151Z",
     "start_time": "2024-07-04T05:52:19.992324Z"
    }
   },
   "outputs": [],
   "source": [
    "# 基本配置\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.embeddings.cloudflare_workersai import CloudflareWorkersAIEmbeddings\n",
    "from supabase.client import Client, create_client\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "qw_llm_openai = ChatOpenAI(\n",
    "    openai_api_base=os.getenv('DASHSCOPE_API_BASE'),\n",
    "    openai_api_key=os.getenv('DASHSCOPE_API_KEY'),\n",
    "    model_name=\"qwen2-1.5b-instruct\",\n",
    "    temperature=0.7,\n",
    "    streaming=True,\n",
    ")\n",
    "embeddings = CloudflareWorkersAIEmbeddings(\n",
    "    account_id=os.getenv('CF_ACCOUNT_ID'),\n",
    "    api_token=os.getenv('CF_API_TOKEN'),\n",
    "    model_name=\"@cf/baai/bge-large-en-v1.5\",\n",
    ")\n",
    "\n",
    "supabase_url = os.environ.get(\"SUPABASE_URL\")\n",
    "supabase_key = os.environ.get(\"SUPABASE_SERVICE_KEY\")\n",
    "\n",
    "supabase: Client = create_client(supabase_url, supabase_key)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m      9\u001B[0m     loader \u001B[38;5;241m=\u001B[39m TextLoader(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(dirpath, file), encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m     docs\u001B[38;5;241m.\u001B[39mextend(\u001B[43mloader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_and_split\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/document_loaders/base.py:64\u001B[0m, in \u001B[0;36mBaseLoader.load_and_split\u001B[0;34m(self, text_splitter)\u001B[0m\n\u001B[1;32m     62\u001B[0m     _text_splitter \u001B[38;5;241m=\u001B[39m text_splitter\n\u001B[1;32m     63\u001B[0m docs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mload()\n\u001B[0;32m---> 64\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_text_splitter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit_documents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdocs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_text_splitters/base.py:96\u001B[0m, in \u001B[0;36mTextSplitter.split_documents\u001B[0;34m(self, documents)\u001B[0m\n\u001B[1;32m     94\u001B[0m     texts\u001B[38;5;241m.\u001B[39mappend(doc\u001B[38;5;241m.\u001B[39mpage_content)\n\u001B[1;32m     95\u001B[0m     metadatas\u001B[38;5;241m.\u001B[39mappend(doc\u001B[38;5;241m.\u001B[39mmetadata)\n\u001B[0;32m---> 96\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_documents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadatas\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_text_splitters/base.py:79\u001B[0m, in \u001B[0;36mTextSplitter.create_documents\u001B[0;34m(self, texts, metadatas)\u001B[0m\n\u001B[1;32m     77\u001B[0m index \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     78\u001B[0m previous_chunk_len \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m---> 79\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit_text\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m     80\u001B[0m     metadata \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(_metadatas[i])\n\u001B[1;32m     81\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_add_start_index:\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_text_splitters/character.py:118\u001B[0m, in \u001B[0;36mRecursiveCharacterTextSplitter.split_text\u001B[0;34m(self, text)\u001B[0m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msplit_text\u001B[39m(\u001B[38;5;28mself\u001B[39m, text: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[\u001B[38;5;28mstr\u001B[39m]:\n\u001B[0;32m--> 118\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_split_text\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_separators\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_text_splitters/character.py:110\u001B[0m, in \u001B[0;36mRecursiveCharacterTextSplitter._split_text\u001B[0;34m(self, text, separators)\u001B[0m\n\u001B[1;32m    108\u001B[0m             final_chunks\u001B[38;5;241m.\u001B[39mappend(s)\n\u001B[1;32m    109\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 110\u001B[0m             other_info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_split_text\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_separators\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    111\u001B[0m             final_chunks\u001B[38;5;241m.\u001B[39mextend(other_info)\n\u001B[1;32m    112\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _good_splits:\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_text_splitters/character.py:113\u001B[0m, in \u001B[0;36mRecursiveCharacterTextSplitter._split_text\u001B[0;34m(self, text, separators)\u001B[0m\n\u001B[1;32m    111\u001B[0m             final_chunks\u001B[38;5;241m.\u001B[39mextend(other_info)\n\u001B[1;32m    112\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _good_splits:\n\u001B[0;32m--> 113\u001B[0m     merged_text \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_merge_splits\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_good_splits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_separator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    114\u001B[0m     final_chunks\u001B[38;5;241m.\u001B[39mextend(merged_text)\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m final_chunks\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_text_splitters/base.py:133\u001B[0m, in \u001B[0;36mTextSplitter._merge_splits\u001B[0;34m(self, splits, separator)\u001B[0m\n\u001B[1;32m    129\u001B[0m     docs\u001B[38;5;241m.\u001B[39mappend(doc)\n\u001B[1;32m    130\u001B[0m \u001B[38;5;66;03m# Keep on popping if:\u001B[39;00m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;66;03m# - we have a larger chunk than in the chunk overlap\u001B[39;00m\n\u001B[1;32m    132\u001B[0m \u001B[38;5;66;03m# - or if we still have any chunks and the length is long\u001B[39;00m\n\u001B[0;32m--> 133\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m total \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chunk_overlap \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m    134\u001B[0m     total \u001B[38;5;241m+\u001B[39m _len \u001B[38;5;241m+\u001B[39m (separator_len \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(current_doc) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    135\u001B[0m     \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chunk_size\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m total \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    137\u001B[0m ):\n\u001B[1;32m    138\u001B[0m     total \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_length_function(current_doc[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m+\u001B[39m (\n\u001B[1;32m    139\u001B[0m         separator_len \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(current_doc) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    140\u001B[0m     )\n\u001B[1;32m    141\u001B[0m     current_doc \u001B[38;5;241m=\u001B[39m current_doc[\u001B[38;5;241m1\u001B[39m:]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "root_dir = '/Users/pangmengting/Documents/workspace/open-webui'\n",
    "docs = []\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    for file in filenames:\n",
    "        try:\n",
    "            loader = TextLoader(os.path.join(dirpath, file), encoding='utf-8')\n",
    "            docs.extend(loader.load_and_split())\n",
    "        except Exception as e:\n",
    "            pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-04T05:53:10.466945Z",
     "start_time": "2024-07-04T05:52:42.209687Z"
    }
   },
   "id": "b5a4a85382020b02",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "53394"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-04T05:53:12.420319Z",
     "start_time": "2024-07-04T05:53:12.416068Z"
    }
   },
   "id": "df26d8c7e0fe1b1b",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "splits = text_splitter.split_documents(docs)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f872e5e83ca0ca55"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(splits)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96fd1b73e2359468"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import SupabaseVectorStore\n",
    "\n",
    "vectorstore = SupabaseVectorStore.from_documents(\n",
    "    splits,\n",
    "    embeddings,\n",
    "    client=supabase,\n",
    "    table_name=\"bge_large_vector\",\n",
    "    query_name=\"bge_large_match_documents\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64b59c25a6b89773"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "retriever.search_kwargs['distance_metric'] = 'cos'\n",
    "retriever.search_kwargs['fetch_k'] = 100\n",
    "retriever.search_kwargs['maximal_marginal_relevance'] = True\n",
    "retriever.search_kwargs['k'] = 10"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b0b1e919a3c41d7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.chains.conversational_retrieval.base import ConversationalRetrievalChain\n",
    "\n",
    "# from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(qw_llm_openai, retriever=retriever)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43579e3bf6082a09"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"What does Chroma do?\",\n",
    "    \"How to use Chroma?\"\n",
    "]\n",
    "chat_history = []\n",
    "\n",
    "for question in questions:\n",
    "    result = qa({\"question\": question, \"chat_history\": chat_history})\n",
    "    chat_history.append((question, result['answer']))\n",
    "    print(f\"Question:\\n {question} \\n\")\n",
    "    print(f\"Answer:\\n {result['answer']} \\n\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cad29cdbc7675b0c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def ask(question, chat_history):\n",
    "    response = qa({\"question\": question, \"chat_history\": chat_history})\n",
    "    print(f\"Question:\\n {question}\\n\")\n",
    "    print(f\"Answer:\\n {response['answer']}\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d336db595e9f7b8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ask(\"What's the main programming language used in Chroma?\", chat_history)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bcf377e293be428"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ask('Show me the public functions of class Client', chat_history)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1f1168452c30c6e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
