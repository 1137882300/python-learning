{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-09T09:45:35.919019Z",
     "start_time": "2024-07-09T09:45:35.482496Z"
    }
   },
   "outputs": [],
   "source": [
    "# 基本配置\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "qw_llm_openai = ChatOpenAI(\n",
    "    openai_api_base=os.getenv('DASHSCOPE_API_BASE'),\n",
    "    openai_api_key=os.getenv('DASHSCOPE_API_KEY'),\n",
    "    model_name=\"qwen2-1.5b-instruct\",\n",
    "    temperature=0,\n",
    "    streaming=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.cloudflare_workersai import CloudflareWorkersAIEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "embedding = CloudflareWorkersAIEmbeddings(\n",
    "    account_id=os.getenv('CF_ACCOUNT_ID'),\n",
    "    api_token=os.getenv('CF_API_TOKEN'),\n",
    "    model_name=\"@cf/baai/bge-small-en-v1.5\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T09:45:37.499550Z",
     "start_time": "2024-07-09T09:45:37.479527Z"
    }
   },
   "id": "38ace70da450d07b",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "import bs4\n",
    "# from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1. Load, chunk and index the contents of the blog to create a retriever.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=embedding)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 2. Incorporate the retriever into a question-answering chain.\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    "    \"\\n\\n\"\n",
    "    \"Previous conversation:\\n{history}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(qw_llm_openai, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T09:45:55.508558Z",
     "start_time": "2024-07-09T09:45:39.305679Z"
    }
   },
   "id": "4f4e31102b1bbbdd",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7e86ea465044522"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## rag + llm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c114687e5810f8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from typing import Optional, Dict\n",
    "from langchain_core.runnables.utils import Input\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "from langchain_core.load import Serializable\n",
    "\n",
    "\n",
    "# 自定义一个继承Runnable的类\n",
    "class StdOutputRunnable(Serializable, Runnable[Input, Input]):\n",
    "    @property\n",
    "    def lc_serializable(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    def invoke(self, input: Dict, config: Optional[RunnableConfig] = None) -> Input:\n",
    "        # print(f\"Hey, I received the name {input['name']}\")\n",
    "        print(input)\n",
    "        return self._call_with_config(lambda x: x, input, config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T06:11:49.374500Z",
     "start_time": "2024-07-09T06:11:49.365496Z"
    }
   },
   "id": "d0418405487f640a",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "# 这个函数接收一个文档列表，并将它们的页面内容（page_content）合并成一个单一的字符串，每个文档之间用两个换行符分隔\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# 执行流程2:\n",
    "# rag_chain_from_docs 使用 retrieve_docs 的输出（问题）和 format_docs 函数来格式化检索到的文档内容。\n",
    "rag_chain_from_docs = (\n",
    "    # 这一步接收 retrieve_docs 函数的输出，将其作为 context 传递给 format_docs 函数，生成格式化的文档内容字符串。\n",
    "        RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"retriever_context\"])))\n",
    "        | prompt\n",
    "        | qw_llm_openai\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 执行流程1: 从字典中提取 input 键的值，即 \"What is Task Decomposition\"。用户的问题\n",
    "# retrieve_docs 函数的输出是一个包含 context 键的字典，那么 x 就会包含这个键\n",
    "retrieve_docs = (lambda x: x[\"input\"]) | retriever\n",
    "# retrieve_docs = (lambda x: {\"retriever_context\": retriever.get_relevant_documents(x[\"input\"])})\n",
    "\n",
    "# 组合\n",
    "# chain：这个变量组合了两个步骤，\n",
    "# 首先通过 retrieve_docs 获取问题，\n",
    "# 然后通过 rag_chain_from_docs 来生成答案。\n",
    "# retriever_context会被传递到下一个步骤里去\n",
    "chain = RunnablePassthrough.assign(retriever_context=retrieve_docs).assign(\n",
    "    answer=rag_chain_from_docs\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T09:46:02.772496Z",
     "start_time": "2024-07-09T09:46:02.755406Z"
    }
   },
   "id": "149c7449ee16086f",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Input to ChatPromptTemplate is missing variables {'history'}.  Expected: ['context', 'history', 'input'] Received: ['input', 'retriever_context', 'context']\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 详细流程：\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# 1. 从字典中提取 input 键的值，即 \"What is Task Decomposition\"。用户的问题\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# 2. 使用 retrieve_docs 函数来检索文档，并把结果赋值给 retriever_context，再传递给下一个步骤（即rag_chain_from_docs）\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# 3. rag_chain_from_docs 使用 retrieve_docs 的输出（问题）和 format_docs 函数来格式化检索到的文档内容。\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mchain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minput\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mWhat is Task Decomposition\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:2507\u001B[0m, in \u001B[0;36mRunnableSequence.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   2505\u001B[0m             \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m step\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;28minput\u001B[39m, config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   2506\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 2507\u001B[0m             \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mstep\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2508\u001B[0m \u001B[38;5;66;03m# finish the root run\u001B[39;00m\n\u001B[1;32m   2509\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/runnables/passthrough.py:469\u001B[0m, in \u001B[0;36mRunnableAssign.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    463\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minvoke\u001B[39m(\n\u001B[1;32m    464\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    465\u001B[0m     \u001B[38;5;28minput\u001B[39m: Dict[\u001B[38;5;28mstr\u001B[39m, Any],\n\u001B[1;32m    466\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    467\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    468\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, Any]:\n\u001B[0;32m--> 469\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_with_config\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_invoke\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:1599\u001B[0m, in \u001B[0;36mRunnable._call_with_config\u001B[0;34m(self, func, input, config, run_type, **kwargs)\u001B[0m\n\u001B[1;32m   1595\u001B[0m     context \u001B[38;5;241m=\u001B[39m copy_context()\n\u001B[1;32m   1596\u001B[0m     context\u001B[38;5;241m.\u001B[39mrun(_set_config_context, child_config)\n\u001B[1;32m   1597\u001B[0m     output \u001B[38;5;241m=\u001B[39m cast(\n\u001B[1;32m   1598\u001B[0m         Output,\n\u001B[0;32m-> 1599\u001B[0m         \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1600\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcall_func_with_variable_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1601\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1602\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1603\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1604\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1605\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1606\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m   1607\u001B[0m     )\n\u001B[1;32m   1608\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1609\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/runnables/config.py:380\u001B[0m, in \u001B[0;36mcall_func_with_variable_args\u001B[0;34m(func, input, config, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    378\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m run_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m accepts_run_manager(func):\n\u001B[1;32m    379\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m run_manager\n\u001B[0;32m--> 380\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/runnables/passthrough.py:456\u001B[0m, in \u001B[0;36mRunnableAssign._invoke\u001B[0;34m(self, input, run_manager, config, **kwargs)\u001B[0m\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_invoke\u001B[39m(\n\u001B[1;32m    444\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    445\u001B[0m     \u001B[38;5;28minput\u001B[39m: Dict[\u001B[38;5;28mstr\u001B[39m, Any],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    448\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    449\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, Any]:\n\u001B[1;32m    450\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\n\u001B[1;32m    451\u001B[0m         \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mdict\u001B[39m\n\u001B[1;32m    452\u001B[0m     ), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe input to RunnablePassthrough.assign() must be a dict.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    454\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[1;32m    455\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m,\n\u001B[0;32m--> 456\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmapper\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    457\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    458\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpatch_config\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    459\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    460\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m    461\u001B[0m     }\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:3152\u001B[0m, in \u001B[0;36mRunnableParallel.invoke\u001B[0;34m(self, input, config)\u001B[0m\n\u001B[1;32m   3139\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m get_executor_for_config(config) \u001B[38;5;28;01mas\u001B[39;00m executor:\n\u001B[1;32m   3140\u001B[0m         futures \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m   3141\u001B[0m             executor\u001B[38;5;241m.\u001B[39msubmit(\n\u001B[1;32m   3142\u001B[0m                 step\u001B[38;5;241m.\u001B[39minvoke,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3150\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m key, step \u001B[38;5;129;01min\u001B[39;00m steps\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m   3151\u001B[0m         ]\n\u001B[0;32m-> 3152\u001B[0m         output \u001B[38;5;241m=\u001B[39m {key: future\u001B[38;5;241m.\u001B[39mresult() \u001B[38;5;28;01mfor\u001B[39;00m key, future \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(steps, futures)}\n\u001B[1;32m   3153\u001B[0m \u001B[38;5;66;03m# finish the root run\u001B[39;00m\n\u001B[1;32m   3154\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:3152\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m   3139\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m get_executor_for_config(config) \u001B[38;5;28;01mas\u001B[39;00m executor:\n\u001B[1;32m   3140\u001B[0m         futures \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m   3141\u001B[0m             executor\u001B[38;5;241m.\u001B[39msubmit(\n\u001B[1;32m   3142\u001B[0m                 step\u001B[38;5;241m.\u001B[39minvoke,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3150\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m key, step \u001B[38;5;129;01min\u001B[39;00m steps\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m   3151\u001B[0m         ]\n\u001B[0;32m-> 3152\u001B[0m         output \u001B[38;5;241m=\u001B[39m {key: \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m key, future \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(steps, futures)}\n\u001B[1;32m   3153\u001B[0m \u001B[38;5;66;03m# finish the root run\u001B[39;00m\n\u001B[1;32m   3154\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:458\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    456\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[1;32m    457\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[0;32m--> 458\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    459\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    460\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:403\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    401\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[1;32m    402\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 403\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[1;32m    404\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    405\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[1;32m    406\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/thread.py:58\u001B[0m, in \u001B[0;36m_WorkItem.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 58\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfuture\u001B[38;5;241m.\u001B[39mset_exception(exc)\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:2507\u001B[0m, in \u001B[0;36mRunnableSequence.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   2505\u001B[0m             \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m step\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;28minput\u001B[39m, config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   2506\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 2507\u001B[0m             \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mstep\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2508\u001B[0m \u001B[38;5;66;03m# finish the root run\u001B[39;00m\n\u001B[1;32m   2509\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/prompts/base.py:151\u001B[0m, in \u001B[0;36mBasePromptTemplate.invoke\u001B[0;34m(self, input, config)\u001B[0m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtags:\n\u001B[1;32m    150\u001B[0m     config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtags\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtags\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtags\n\u001B[0;32m--> 151\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_with_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    152\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_format_prompt_with_error_handling\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    153\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrun_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprompt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:1599\u001B[0m, in \u001B[0;36mRunnable._call_with_config\u001B[0;34m(self, func, input, config, run_type, **kwargs)\u001B[0m\n\u001B[1;32m   1595\u001B[0m     context \u001B[38;5;241m=\u001B[39m copy_context()\n\u001B[1;32m   1596\u001B[0m     context\u001B[38;5;241m.\u001B[39mrun(_set_config_context, child_config)\n\u001B[1;32m   1597\u001B[0m     output \u001B[38;5;241m=\u001B[39m cast(\n\u001B[1;32m   1598\u001B[0m         Output,\n\u001B[0;32m-> 1599\u001B[0m         \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1600\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcall_func_with_variable_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1601\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1602\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1603\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1604\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1605\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1606\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m   1607\u001B[0m     )\n\u001B[1;32m   1608\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1609\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/runnables/config.py:380\u001B[0m, in \u001B[0;36mcall_func_with_variable_args\u001B[0;34m(func, input, config, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    378\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m run_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m accepts_run_manager(func):\n\u001B[1;32m    379\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m run_manager\n\u001B[0;32m--> 380\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/prompts/base.py:134\u001B[0m, in \u001B[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001B[0;34m(self, inner_input)\u001B[0m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_format_prompt_with_error_handling\u001B[39m(\u001B[38;5;28mself\u001B[39m, inner_input: Dict) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m PromptValue:\n\u001B[0;32m--> 134\u001B[0m     _inner_input \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_input\u001B[49m\u001B[43m(\u001B[49m\u001B[43minner_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    135\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mformat_prompt(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_inner_input)\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/prompts/base.py:126\u001B[0m, in \u001B[0;36mBasePromptTemplate._validate_input\u001B[0;34m(self, inner_input)\u001B[0m\n\u001B[1;32m    124\u001B[0m missing \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_variables)\u001B[38;5;241m.\u001B[39mdifference(inner_input)\n\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m missing:\n\u001B[0;32m--> 126\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\n\u001B[1;32m    127\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInput to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is missing variables \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmissing\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    128\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Expected: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_variables\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    129\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Received: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(inner_input\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    130\u001B[0m     )\n\u001B[1;32m    131\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m inner_input\n",
      "\u001B[0;31mKeyError\u001B[0m: \"Input to ChatPromptTemplate is missing variables {'history'}.  Expected: ['context', 'history', 'input'] Received: ['input', 'retriever_context', 'context']\""
     ]
    }
   ],
   "source": [
    "\n",
    "# 详细流程：\n",
    "# 1. 从字典中提取 input 键的值，即 \"What is Task Decomposition\"。用户的问题\n",
    "# 2. 使用 retrieve_docs 函数来检索文档，并把结果赋值给 retriever_context，再传递给下一个步骤（即rag_chain_from_docs）\n",
    "# 3. rag_chain_from_docs 使用 retrieve_docs 的输出（问题）和 format_docs 函数来格式化检索到的文档内容。\n",
    "result = chain.invoke({\"input\": \"What is Task Decomposition\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T09:46:09.216570Z",
     "start_time": "2024-07-09T09:46:05.785318Z"
    }
   },
   "id": "c133b330361fb8a6",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## rag + memory + llm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e0786f5d8b215f6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory\n",
    "from langchain.memory.chat_message_histories import FileChatMessageHistory\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    "    \"\\n\\n\"\n",
    "    \"Previous conversation:\\n{history}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# memory1\n",
    "# memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "# memory2\n",
    "path = '../../../data/history/conversation_20240709-2.json'\n",
    "message_history = FileChatMessageHistory(file_path=path)\n",
    "# memory = ConversationBufferMemory(chat_memory=message_history, return_messages=True)\n",
    "\n",
    "# memory3\n",
    "memory = ConversationBufferWindowMemory(k=2, chat_memory=message_history, return_messages=True)\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "        RunnablePassthrough.assign(\n",
    "            context=(lambda x: format_docs(x[\"retriever_context\"])),\n",
    "            history=memory.load_memory_variables\n",
    "        )\n",
    "        | prompt\n",
    "        | qw_llm_openai\n",
    "        | StrOutputParser()\n",
    ")\n",
    "retrieve_docs = (lambda x: x[\"input\"]) | retriever\n",
    "# retrieve_docs = lambda x: {\"retriever_context\": retriever.get_relevant_documents(x[\"input\"])}\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(retriever_context=retrieve_docs)\n",
    "    .assign(answer=rag_chain_from_docs)\n",
    "    .assign(\n",
    "        memory_update=lambda x: memory.save_context(\n",
    "            {\"input\": x[\"input\"]},\n",
    "            {\"output\": x[\"answer\"]}\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# 使用示例\n",
    "def chat(input_text):\n",
    "    result = chain.invoke({\"input\": input_text})\n",
    "    return result[\"answer\"]\n",
    "\n",
    "# 使用方法\n",
    "# response = chat(\"What is Task Decomposition?\")\n",
    "# print(response)\n",
    "# 继续对话\n",
    "# response = chat(\"Can you give me an example?\")\n",
    "# print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T09:46:42.464291Z",
     "start_time": "2024-07-09T09:46:42.431723Z"
    }
   },
   "id": "c40e73a5bc0256ab",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Decomposition is a method used to break down complex tasks into smaller, more manageable ones. It involves breaking down a task into multiple steps or subtasks and then analyzing the model's thinking process to understand how it plans and solves problems. This technique helps in improving the efficiency and effectiveness of the model when faced with difficult tasks.\n"
     ]
    }
   ],
   "source": [
    "response = chat(\"What is Task Decomposition?\")\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T09:46:46.921903Z",
     "start_time": "2024-07-09T09:46:44.439563Z"
    }
   },
   "id": "281c1d1e6784e97e",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"The user wants an example of task decomposition.\",\n",
      "        \"reasoning\": \"I will provide an example of how task decomposition works in a simple scenario.\",\n",
      "        \"plan\": \"- Provide an example of task decomposition\\n- Explain how it breaks down the task into smaller parts\\n- Suggest that the user provides feedback on whether they understood the concept\",\n",
      "        \"criticism\": \"It's important to ensure the explanation is clear and understandable.\",\n",
      "        \"speak\": \"Sure, here's an example: Imagine you're organizing a party. You have a list of tasks to complete: buy decorations, invite guests, prepare food, etc. By breaking this task into smaller sub-tasks such as buying decorations, inviting guests, and preparing food, you can manage each part of the event more effectively.\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"command name\",\n",
      "        \"args\": {\n",
      "            \"arg name\": \"value\"\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = chat(\"Can you give me an example?\")\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T03:14:11.883029Z",
     "start_time": "2024-07-09T03:14:08.805918Z"
    }
   },
   "id": "56224058cd4f353a",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你之前问的问题是关于\"Task Decomposition\"的概念。\n"
     ]
    }
   ],
   "source": [
    "response = chat(\"我刚才问了什么,hhhh?\")\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T03:14:50.596266Z",
     "start_time": "2024-07-09T03:14:48.678355Z"
    }
   },
   "id": "be27c11fb81420aa",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method ConversationBufferMemory.load_memory_variables of ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='What is Task Decomposition?'), AIMessage(content='Task Decomposition is a method used in artificial intelligence where a large task is broken down into smaller, more manageable parts called subtasks. This approach helps the AI system understand the task better and perform it more efficiently.'), HumanMessage(content='Can you give me an example?'), AIMessage(content='{\\n    \"thoughts\": {\\n        \"text\": \"The user wants an example of task decomposition.\",\\n        \"reasoning\": \"I will provide an example of how task decomposition works in a simple scenario.\",\\n        \"plan\": \"- Provide an example of task decomposition\\\\n- Explain how it breaks down the task into smaller parts\\\\n- Suggest that the user provides feedback on whether they understood the concept\",\\n        \"criticism\": \"It\\'s important to ensure the explanation is clear and understandable.\",\\n        \"speak\": \"Sure, here\\'s an example: Let\\'s break down the task of cooking a meal.\"\\n    },\\n    \"command\": {\\n        \"name\": \"command name\",\\n        \"args\": {\\n            \"arg name\": \"value\"\\n        }\\n    }\\n}'), HumanMessage(content='我刚才问了什么?'), AIMessage(content='你之前问的问题是关于\"Task Decomposition\"的概念。')]), return_messages=True)>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T02:53:59.816774Z",
     "start_time": "2024-07-09T02:53:59.805268Z"
    }
   },
   "id": "745c6b4612222ebd",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[HumanMessage(content='What is Task Decomposition?'),\n AIMessage(content='Task Decomposition is a method used in artificial intelligence where a large task is broken down into smaller, more manageable parts called subtasks. This approach helps the AI system understand the task better and perform it more efficiently.'),\n HumanMessage(content='Can you give me an example?'),\n AIMessage(content='{\\n    \"thoughts\": {\\n        \"text\": \"The user wants an example of task decomposition.\",\\n        \"reasoning\": \"I will provide an example of how task decomposition works in a simple scenario.\",\\n        \"plan\": \"- Provide an example of task decomposition\\\\n- Explain how it breaks down the task into smaller parts\\\\n- Suggest that the user provides feedback on whether they understood the concept\",\\n        \"criticism\": \"It\\'s important to ensure the explanation is clear and understandable.\",\\n        \"speak\": \"Sure, here\\'s an example: Let\\'s break down the task of cooking a meal.\"\\n    },\\n    \"command\": {\\n        \"name\": \"command name\",\\n        \"args\": {\\n            \"arg name\": \"value\"\\n        }\\n    }\\n}'),\n HumanMessage(content='我刚才问了什么?'),\n AIMessage(content='你之前问的问题是关于\"Task Decomposition\"的概念。')]"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory.messages"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T03:03:55.706434Z",
     "start_time": "2024-07-09T03:03:55.698031Z"
    }
   },
   "id": "a95130af15c4656b",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "result = chain.invoke({\"input\": 'What is Task Decomposition?'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T09:47:28.778841Z",
     "start_time": "2024-07-09T09:47:24.870900Z"
    }
   },
   "id": "9f544a9533e5df0a",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'input': 'What is Task Decomposition?',\n 'retriever_context': [Document(page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}),\n  Document(page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}),\n  Document(page_content='The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}),\n  Document(page_content='Fig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'})],\n 'answer': \"Task Decomposition is a method used to break down complex tasks into smaller, more manageable ones. It involves breaking down a task into multiple steps or subtasks and then analyzing the model's thinking process to understand how it plans and solves problems. This technique helps in improving the efficiency and effectiveness of the model when faced with difficult tasks.\",\n 'memory_update': None}"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T10:18:52.144815Z",
     "start_time": "2024-07-09T10:18:52.139923Z"
    }
   },
   "id": "adb9d561c8b1e7af",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://lilianweng.github.io/posts/2023-06-23-agent/\n",
      "https://lilianweng.github.io/posts/2023-06-23-agent/\n",
      "https://lilianweng.github.io/posts/2023-06-23-agent/\n",
      "https://lilianweng.github.io/posts/2023-06-23-agent/\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'},\n {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'},\n {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'},\n {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}]"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result['retriever_context'][0].metadata\n",
    "back_list=[]\n",
    "for back in result['retriever_context']:\n",
    "    print(back.metadata['source'])\n",
    "    back_list.append(back.metadata)\n",
    "\n",
    "back_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T10:32:54.309137Z",
     "start_time": "2024-07-09T10:32:54.302480Z"
    }
   },
   "id": "297cb294fd161d4a",
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 方式2 RunnableWithMessageHistory"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27ddb2370752ec5a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "        RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"retriever_context\"])))\n",
    "        | prompt\n",
    "        | qw_llm_openai\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "retrieve_docs = (lambda x: x[\"input\"]) | retriever\n",
    "# retrieve_docs = lambda x: {\"retriever_context\": retriever.get_relevant_documents(x[\"input\"])}\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(retriever_context=retrieve_docs)\n",
    "    .assign(answer=rag_chain_from_docs)\n",
    ")\n",
    "\n",
    "\n",
    "def get_session_history():\n",
    "    return ChatMessageHistory()\n",
    "\n",
    "\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "\n",
    "# 使用示例\n",
    "def chat(input_text, session_id):\n",
    "    result = chain_with_history.invoke(\n",
    "        {\"input\": input_text},\n",
    "        config={\"configurable\": {\"session_id\": session_id}}\n",
    "    )\n",
    "    return result[\"answer\"]\n",
    "\n",
    "# 使用方法\n",
    "# response = chat(\"What is Task Decomposition?\", \"user_1\")\n",
    "# print(response)\n",
    "# 继续对话\n",
    "# response = chat(\"Can you give me an example?\", \"user_1\")\n",
    "# print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T03:02:28.235517Z",
     "start_time": "2024-07-09T03:02:28.224171Z"
    }
   },
   "id": "5d6bb9707ca81a6b",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_session_history() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[35], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mchat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mWhat is Task Decomposition?\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser_1\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(response)\n",
      "Cell \u001B[0;32mIn[34], line 60\u001B[0m, in \u001B[0;36mchat\u001B[0;34m(input_text, session_id)\u001B[0m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mchat\u001B[39m(input_text, session_id):\n\u001B[0;32m---> 60\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mchain_with_history\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     61\u001B[0m \u001B[43m        \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minput\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_text\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     62\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mconfigurable\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msession_id\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43msession_id\u001B[49m\u001B[43m}\u001B[49m\u001B[43m}\u001B[49m\n\u001B[1;32m     63\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     64\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124manswer\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:4590\u001B[0m, in \u001B[0;36mRunnableBindingBase.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   4582\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minvoke\u001B[39m(\n\u001B[1;32m   4583\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   4584\u001B[0m     \u001B[38;5;28minput\u001B[39m: Input,\n\u001B[1;32m   4585\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   4586\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Optional[Any],\n\u001B[1;32m   4587\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Output:\n\u001B[1;32m   4588\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbound\u001B[38;5;241m.\u001B[39minvoke(\n\u001B[1;32m   4589\u001B[0m         \u001B[38;5;28minput\u001B[39m,\n\u001B[0;32m-> 4590\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_merge_configs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m   4591\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m{\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs},\n\u001B[1;32m   4592\u001B[0m     )\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/runnables/history.py:544\u001B[0m, in \u001B[0;36mRunnableWithMessageHistory._merge_configs\u001B[0;34m(self, *configs)\u001B[0m\n\u001B[1;32m    540\u001B[0m parameter_names \u001B[38;5;241m=\u001B[39m _get_parameter_names(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_session_history)\n\u001B[1;32m    542\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(expected_keys) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    543\u001B[0m     \u001B[38;5;66;03m# If arity = 1, then invoke function by positional arguments\u001B[39;00m\n\u001B[0;32m--> 544\u001B[0m     message_history \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_session_history\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfigurable\u001B[49m\u001B[43m[\u001B[49m\u001B[43mexpected_keys\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    545\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    546\u001B[0m     \u001B[38;5;66;03m# otherwise verify that names of keys patch and invoke by named arguments\u001B[39;00m\n\u001B[1;32m    547\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mset\u001B[39m(expected_keys) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mset\u001B[39m(parameter_names):\n",
      "\u001B[0;31mTypeError\u001B[0m: get_session_history() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "response = chat(\"What is Task Decomposition?\", \"user_1\")\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T03:02:34.853862Z",
     "start_time": "2024-07-09T03:02:34.692379Z"
    }
   },
   "id": "96af98a76b7f67ff",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "牛背山你知道吗\n"
     ]
    }
   ],
   "source": [
    "# 假设 content 是一个包含 Unicode 编码的字符串\n",
    "content = b'\\u725b\\u80cc\\u5c71\\u4f60\\u77e5\\u9053\\u5417'\n",
    "\n",
    "# 使用 decode 方法将编码的字符串转换为正常的中文字符\n",
    "decoded_content = content.decode('unicode_escape')\n",
    "\n",
    "print(decoded_content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T03:57:40.971513Z",
     "start_time": "2024-07-09T03:57:40.966307Z"
    }
   },
   "id": "13f7d0fb8880a3b0",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\u725b\\u80cc\\u5c71\\u4f60\\u77e5\\u9053\\u5417\n"
     ]
    }
   ],
   "source": [
    "# 假设 byte_content 是从外部获取的字节序列\n",
    "byte_content = b'\\xe7\\x88\\x86\\xe8\\x99\\x8e\\xe5\\xb1\\xb1\\xe4\\xbd\\xa0\\xe7\\x9f\\xa5\\xe9\\x81\\x93\\xe5\\x90\\x97'\n",
    "\n",
    "# 使用 decode 方法将字节序列解码为字符串\n",
    "content = content.decode('utf-8')\n",
    "\n",
    "print(content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T03:57:43.838185Z",
     "start_time": "2024-07-09T03:57:43.834515Z"
    }
   },
   "id": "7b47a32fd71a2f5c",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ff27f02e6ec67669"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
