{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-08T03:26:31.094842Z",
     "start_time": "2024-07-08T03:26:31.026478Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 基本配置\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.embeddings.cloudflare_workersai import CloudflareWorkersAIEmbeddings\n",
    "from supabase.client import Client, create_client\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "qw_llm_openai = ChatOpenAI(\n",
    "    openai_api_base=os.getenv('DASHSCOPE_API_BASE'),\n",
    "    openai_api_key=os.getenv('DASHSCOPE_API_KEY'),\n",
    "    model_name=\"qwen2-1.5b-instruct\",\n",
    "    temperature=0,\n",
    "    streaming=True,\n",
    ")\n",
    "# embedding = CloudflareWorkersAIEmbeddings(\n",
    "#     account_id=os.getenv('CF_ACCOUNT_ID'),\n",
    "#     api_token=os.getenv('CF_API_TOKEN'),\n",
    "#     model_name=\"@cf/baai/bge-small-en-v1.5\",\n",
    "# )\n",
    "# \n",
    "# supabase_url = os.environ.get(\"SUPABASE_URL\")\n",
    "# supabase_key = os.environ.get(\"SUPABASE_SERVICE_KEY\")\n",
    "# \n",
    "# supabase: Client = create_client(supabase_url, supabase_key)\n",
    "# \n",
    "# collection_name = 'yxk-robus-index'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T03:26:18.376915Z",
     "start_time": "2024-07-08T03:26:17.798827Z"
    }
   },
   "id": "c2a65c721149b207",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def track_tokens_usage(chain, query):\n",
    "    with get_openai_callback() as cb:\n",
    "        result = chain.invoke(query)\n",
    "        print(f'Total tokens: {cb.total_tokens}')\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T03:46:26.693450Z",
     "start_time": "2024-07-08T03:46:26.680200Z"
    }
   },
   "id": "11e5cec75ee4c0a8",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用Memory组件ConversationBufferMemory的默认配置"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1205270b207e0c12"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "conversation = ConversationChain(llm=qw_llm_openai, memory=ConversationBufferMemory())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T03:46:29.505732Z",
     "start_time": "2024-07-08T03:46:29.502480Z"
    }
   },
   "id": "9379cb59b98ab7c",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "print(conversation.prompt.template)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T03:46:30.956085Z",
     "start_time": "2024-07-08T03:46:30.952163Z"
    }
   },
   "id": "cb4245d4976055a7",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 11:46:32,593:INFO - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'What is Langchain?',\n 'history': '',\n 'response': 'LangChain is a library for implementing language models in Python that can be used with PyTorch or TensorFlow. It was developed by OpenAI as part of their research project called \"Language Models Are Far From Ready\". The goal of this project was to create a high-performance language model that could generate text at scale.'}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_tokens_usage(conversation, \"What is Langchain?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T03:46:32.966363Z",
     "start_time": "2024-07-08T03:46:32.186679Z"
    }
   },
   "id": "755f7d852788b6ab",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "引入消息历史持久化组件"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96a857b3ef48bcf8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.memory.chat_message_histories import FileChatMessageHistory\n",
    "\n",
    "path = '../../data/history/conversation_20240708.json'\n",
    "message_history = FileChatMessageHistory(file_path=path)\n",
    "memory = ConversationBufferMemory(chat_memory=message_history)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T03:52:06.095431Z",
     "start_time": "2024-07-08T03:52:06.088968Z"
    }
   },
   "id": "64b85df744c64a66",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "conversation = ConversationChain(llm=qw_llm_openai, memory=memory)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T03:52:41.918558Z",
     "start_time": "2024-07-08T03:52:41.912937Z"
    }
   },
   "id": "f547d8eed4bbfbea",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 11:49:29,045:INFO - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'How does ChatGPT enable coherent conversation?',\n 'history': '',\n 'response': \"ChatGPT enables coherent conversation by using natural language processing (NLP) techniques to analyze the input from the user and generate a response that is grammatically correct, relevant, and coherent with the previous statements or questions asked. This process involves breaking down the input into smaller pieces, identifying patterns and relationships in the text, and then generating a response that fits the context and tone of the conversation. Additionally, ChatGPT uses machine learning algorithms to improve its ability to understand and respond to different types of inputs over time. By analyzing the user's interactions with ChatGPT, the system learns what works well and what doesn't, allowing it to adjust its behavior accordingly. Overall, ChatGPT's ability to generate coherent responses is due to its advanced NLP capabilities, as well as its use of machine learning algorithms for continuous improvement.\"}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_tokens_usage(conversation, \"How does ChatGPT enable coherent conversation?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T03:49:30.314191Z",
     "start_time": "2024-07-08T03:49:28.753430Z"
    }
   },
   "id": "5660666329db48",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"type\": \"human\", \"data\": {\"content\": \"How does ChatGPT enable coherent conversation?\", \"additional_kwargs\": {}, \"response_metadata\": {}, \"type\": \"human\", \"name\": null, \"id\": null, \"example\": false}}, {\"type\": \"ai\", \"data\": {\"content\": \"ChatGPT enables coherent conversation by using natural language processing (NLP) techniques to analyze the input from the user and generate a response that is grammatically correct, relevant, and coherent with the previous statements or questions asked. This process involves breaking down the input into smaller pieces, identifying patterns and relationships in the text, and then generating a response that fits the context and tone of the conversation. Additionally, ChatGPT uses machine learning algorithms to improve its ability to understand and respond to different types of inputs over time. By analyzing the user's interactions with ChatGPT, the system learns what works well and what doesn't, allowing it to adjust its behavior accordingly. Overall, ChatGPT's ability to generate coherent responses is due to its advanced NLP capabilities, as well as its use of machine learning algorithms for continuous improvement.\", \"additional_kwargs\": {}, \"response_metadata\": {}, \"type\": \"ai\", \"name\": null, \"id\": null, \"example\": false, \"tool_calls\": [], \"invalid_tool_calls\": [], \"usage_metadata\": null}}]"
     ]
    }
   ],
   "source": [
    "!cat ../../data/history/conversation_20240708.txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T03:50:57.726151Z",
     "start_time": "2024-07-08T03:50:57.581451Z"
    }
   },
   "id": "7011c0d3364f0a30",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 11:51:09,804:INFO - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'Bye now!',\n 'history': \"Human: How does ChatGPT enable coherent conversation?\\nAI: ChatGPT enables coherent conversation by using natural language processing (NLP) techniques to analyze the input from the user and generate a response that is grammatically correct, relevant, and coherent with the previous statements or questions asked. This process involves breaking down the input into smaller pieces, identifying patterns and relationships in the text, and then generating a response that fits the context and tone of the conversation. Additionally, ChatGPT uses machine learning algorithms to improve its ability to understand and respond to different types of inputs over time. By analyzing the user's interactions with ChatGPT, the system learns what works well and what doesn't, allowing it to adjust its behavior accordingly. Overall, ChatGPT's ability to generate coherent responses is due to its advanced NLP capabilities, as well as its use of machine learning algorithms for continuous improvement.\",\n 'response': 'Bye! Have a great day!'}"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_tokens_usage(conversation, \"Bye now!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T03:51:09.965906Z",
     "start_time": "2024-07-08T03:51:09.419199Z"
    }
   },
   "id": "3b2a2847479d9d02",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 11:52:45,459:INFO - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'how do use RAG!',\n 'history': \"Human: How does ChatGPT enable coherent conversation?\\nAI: ChatGPT enables coherent conversation by using natural language processing (NLP) techniques to analyze the input from the user and generate a response that is grammatically correct, relevant, and coherent with the previous statements or questions asked. This process involves breaking down the input into smaller pieces, identifying patterns and relationships in the text, and then generating a response that fits the context and tone of the conversation. Additionally, ChatGPT uses machine learning algorithms to improve its ability to understand and respond to different types of inputs over time. By analyzing the user's interactions with ChatGPT, the system learns what works well and what doesn't, allowing it to adjust its behavior accordingly. Overall, ChatGPT's ability to generate coherent responses is due to its advanced NLP capabilities, as well as its use of machine learning algorithms for continuous improvement.\\nHuman: Bye now!\\nAI: Bye! Have a great day!\",\n 'response': 'RAG stands for \"Reactive Artificial General Intelligence,\" which refers to an artificial intelligence model that can be trained to perform tasks similar to those performed by humans. RAGs are designed to be able to adapt to new situations and learn from their experiences, making them particularly useful in complex environments where traditional AI models may struggle.\\nTo use RAG, you would typically need to have access to a pre-trained RAG model that has been trained on a large dataset of examples. Once you have the model, you can ask it to perform a task by providing it with instructions or prompts. For example, if you wanted to use RAG to write a story about a cat, you could give it a list of characters, settings, and plot points to work with, and it would use its natural language processing abilities to generate a coherent and engaging narrative.\\nIt\\'s worth noting that RAGs are still relatively new and developing technologies, so there are limitations to their capabilities and potential applications. However, they hold great promise for future advancements in artificial intelligence and natural language processing.'}"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_tokens_usage(conversation, \"how do use RAG!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T03:52:47.469491Z",
     "start_time": "2024-07-08T03:52:45.102996Z"
    }
   },
   "id": "366dd50abf0f4d7c",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "281b388551c24421"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
