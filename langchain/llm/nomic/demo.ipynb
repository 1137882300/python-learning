{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-05T02:16:44.064763Z",
     "start_time": "2024-08-05T02:16:35.648907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install -q -U  langchain-nomic \n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 基本配置\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "qw_llm_openai = ChatOpenAI(\n",
    "    openai_api_base=os.getenv('DASHSCOPE_API_BASE'),\n",
    "    openai_api_key=os.getenv('DASHSCOPE_API_KEY'),\n",
    "    model_name=\"qwen2-1.5b-instruct\",\n",
    "    temperature=0,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "ms_llm_openai = ChatOpenAI(\n",
    "    openai_api_base=os.getenv('MOONSHOT_API_BASE'),\n",
    "    openai_api_key=os.getenv('MOONSHOT_API_KEY'),\n",
    "    model_name=\"moonshot-v1-8k\",\n",
    "    temperature=0,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "cf_llm_openai = ChatOpenAI(\n",
    "    openai_api_base=os.getenv('CF_API_BASE'),\n",
    "    openai_api_key=os.getenv('CF_API_TOKEN'),\n",
    "    # model_name=\"@cf/meta/llama-3-8b-instruct\",\n",
    "    model_name=\"@cf/meta/llama-3.1-8b-instruct\",\n",
    "    temperature=0,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "groq_llm_openai = ChatOpenAI(\n",
    "    openai_api_base=os.getenv('GROQ_API_BASE'),\n",
    "    openai_api_key=os.getenv('GROQ_API_KEY'),\n",
    "    model_name=\"llama3-8b-8192\",\n",
    "    temperature=0,\n",
    "    streaming=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T02:18:16.153862Z",
     "start_time": "2024-08-05T02:18:15.500159Z"
    }
   },
   "id": "96d0ba68e3ee3619",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "POST_URL = \"https://blog.nomic.ai/posts/nomic-embed-text-v1\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T02:19:35.570085Z",
     "start_time": "2024-08-05T02:19:35.563745Z"
    }
   },
   "id": "4b349bf6e8e3f68f",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "docs = WebBaseLoader(POST_URL).load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T02:19:37.725331Z",
     "start_time": "2024-08-05T02:19:36.104049Z"
    }
   },
   "id": "38416a449214e22d",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T02:19:43.098393Z",
     "start_time": "2024-08-05T02:19:43.067739Z"
    }
   },
   "id": "c9cdd94276d5050d",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=7500, chunk_overlap=100\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T02:19:49.215913Z",
     "start_time": "2024-08-05T02:19:45.542988Z"
    }
   },
   "id": "181c1f17ff407ebc",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AliasChoices' from 'pydantic' (/Users/pangmengting/venv/lib/python3.10/site-packages/pydantic/__init__.cpython-310-darwin.so)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_core\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrunnables\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RunnableLambda, RunnablePassthrough\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# from langchain_nomic import NomicEmbeddings\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_nomic\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01membeddings\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m NomicEmbeddings\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_nomic/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_nomic\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01membeddings\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m NomicEmbeddings\n\u001B[1;32m      3\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNomicEmbeddings\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_nomic/embeddings.py:4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m List, Literal, Optional, overload\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnomic\u001B[39;00m  \u001B[38;5;66;03m# type: ignore[import]\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_core\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01membeddings\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Embeddings\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnomic\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m embed\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/nomic/__init__.py:2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcli\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m login\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataset\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AtlasDataset, AtlasUser\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/nomic/dataset.py:25\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tqdm\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcli\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m refresh_bearer_token, validate_api_http_response\n\u001B[0;32m---> 25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata_inference\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     26\u001B[0m     NomicDuplicatesOptions,\n\u001B[1;32m     27\u001B[0m     NomicEmbedOptions,\n\u001B[1;32m     28\u001B[0m     NomicProjectOptions,\n\u001B[1;32m     29\u001B[0m     NomicTopicOptions,\n\u001B[1;32m     30\u001B[0m     convert_pyarrow_schema_for_atlas,\n\u001B[1;32m     31\u001B[0m )\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata_operations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AtlasMapData, AtlasMapDuplicates, AtlasMapEmbeddings, AtlasMapTags, AtlasMapTopics\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msettings\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/nomic/data_inference.py:4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Any, Dict, List, Literal, Optional, Union\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpyarrow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpa\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpydantic\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AliasChoices, BaseModel, Field\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msettings\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DEFAULT_DUPLICATE_THRESHOLD\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfrom_list\u001B[39m(values: Dict[\u001B[38;5;28mstr\u001B[39m, Any], schema\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m pa\u001B[38;5;241m.\u001B[39mTable:\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'AliasChoices' from 'pydantic' (/Users/pangmengting/venv/lib/python3.10/site-packages/pydantic/__init__.cpython-310-darwin.so)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T02:20:12.332111Z",
     "start_time": "2024-08-05T02:20:12.222973Z"
    }
   },
   "id": "1fb21b11d08c3950",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AliasChoices' from 'pydantic' (/Users/pangmengting/venv/lib/python3.10/site-packages/pydantic/__init__.cpython-310-darwin.so)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_nomic\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m NomicEmbeddings\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_nomic\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01membeddings\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m NomicEmbeddings\n\u001B[1;32m      3\u001B[0m vectorstore \u001B[38;5;241m=\u001B[39m Chroma\u001B[38;5;241m.\u001B[39mfrom_documents(\n\u001B[1;32m      4\u001B[0m     persist_directory\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/Users/pangmengting/Documents/workspace/python-learning/data/chroma_vector_db\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      5\u001B[0m     documents\u001B[38;5;241m=\u001B[39mdoc_splits,\n\u001B[1;32m      6\u001B[0m     embedding\u001B[38;5;241m=\u001B[39mNomicEmbeddings(model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnomic-embed-text-v1\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m      7\u001B[0m )\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_nomic/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_nomic\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01membeddings\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m NomicEmbeddings\n\u001B[1;32m      3\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNomicEmbeddings\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_nomic/embeddings.py:4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m List, Literal, Optional, overload\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnomic\u001B[39;00m  \u001B[38;5;66;03m# type: ignore[import]\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_core\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01membeddings\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Embeddings\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnomic\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m embed\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/nomic/__init__.py:2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcli\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m login\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataset\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AtlasDataset, AtlasUser\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/nomic/dataset.py:25\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tqdm\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcli\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m refresh_bearer_token, validate_api_http_response\n\u001B[0;32m---> 25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata_inference\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     26\u001B[0m     NomicDuplicatesOptions,\n\u001B[1;32m     27\u001B[0m     NomicEmbedOptions,\n\u001B[1;32m     28\u001B[0m     NomicProjectOptions,\n\u001B[1;32m     29\u001B[0m     NomicTopicOptions,\n\u001B[1;32m     30\u001B[0m     convert_pyarrow_schema_for_atlas,\n\u001B[1;32m     31\u001B[0m )\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata_operations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AtlasMapData, AtlasMapDuplicates, AtlasMapEmbeddings, AtlasMapTags, AtlasMapTopics\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msettings\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/nomic/data_inference.py:4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Any, Dict, List, Literal, Optional, Union\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpyarrow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpa\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpydantic\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AliasChoices, BaseModel, Field\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msettings\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DEFAULT_DUPLICATE_THRESHOLD\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfrom_list\u001B[39m(values: Dict[\u001B[38;5;28mstr\u001B[39m, Any], schema\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m pa\u001B[38;5;241m.\u001B[39mTable:\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'AliasChoices' from 'pydantic' (/Users/pangmengting/venv/lib/python3.10/site-packages/pydantic/__init__.cpython-310-darwin.so)"
     ]
    }
   ],
   "source": [
    "from langchain_nomic import NomicEmbeddings\n",
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "vectorstore = Chroma.from_documents(\n",
    "    persist_directory='/Users/pangmengting/Documents/workspace/python-learning/data/chroma_vector_db',\n",
    "    documents=doc_splits,\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1\"),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T02:25:34.118274Z",
     "start_time": "2024-08-05T02:25:34.025093Z"
    }
   },
   "id": "8ab29ef45f1213e3",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Prompt\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | cf_llm_openai\n",
    "        | StrOutputParser()\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ef201f566beeeb0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "response = chain.invoke(\"How did Nomic Embed get trained?\")\n",
    "response"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3db4757497a693c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "AIMessage(content='Nǐ hǎo! (Nice to meet you too!) How can I assist you today?', id='run-04bb9c8a-dd7f-47d1-8130-ad3acd9313ba-0')"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_llm_openai.invoke(\"nihao\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T02:22:02.393675Z",
     "start_time": "2024-08-05T02:21:59.279313Z"
    }
   },
   "id": "113e10c70de871d0",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pydantic\r\n",
      "Version: 1.10.17\r\n",
      "Summary: Data validation and settings management using python type hints\r\n",
      "Home-page: https://github.com/pydantic/pydantic\r\n",
      "Author: Samuel Colvin\r\n",
      "Author-email: s@muelcolvin.com\r\n",
      "License: MIT\r\n",
      "Location: /Users/pangmengting/venv/lib/python3.10/site-packages\r\n",
      "Requires: typing-extensions\r\n",
      "Required-by: anthropic, chainlit, chromadb, cloudflare, docarray, fastapi, google-generativeai, gotrue, kor, langchain, langchain-app, langchain-core, langchainplus-sdk, langserve, langsmith, literalai, llamaindex-py-client, nomic, openai, openapi-schema-pydantic, pandasai, postgrest, pyautogen, qdrant-client, qianfan, sqlmodel, zhipuai\r\n"
     ]
    }
   ],
   "source": [
    "!pip show pydantic\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T02:25:12.600345Z",
     "start_time": "2024-08-05T02:25:10.905132Z"
    }
   },
   "id": "30c31691bc816a70",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Collecting pydantic==1.10.17\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/5d/1e/0bc197ae94b9096a0ee1819532085b847a54a3610f6b51be027567341e80/pydantic-1.10.17-cp310-cp310-macosx_11_0_arm64.whl (2.3 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.3/2.3 MB\u001B[0m \u001B[31m3.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m0m\r\n",
      "\u001B[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /Users/pangmengting/venv/lib/python3.10/site-packages (from pydantic==1.10.17) (4.12.2)\r\n",
      "Installing collected packages: pydantic\r\n",
      "  Attempting uninstall: pydantic\r\n",
      "    Found existing installation: pydantic 2.8.2\r\n",
      "    Uninstalling pydantic-2.8.2:\r\n",
      "      Successfully uninstalled pydantic-2.8.2\r\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "anthropic 0.3.6 requires anyio<4,>=3.5.0, but you have anyio 4.4.0 which is incompatible.\r\n",
      "chainlit 1.1.306 requires packaging<24.0,>=23.1, but you have packaging 24.1 which is incompatible.\r\n",
      "chainlit 1.1.306 requires uvicorn<0.26.0,>=0.25.0, but you have uvicorn 0.23.2 which is incompatible.\r\n",
      "sqlmodel 0.0.8 requires SQLAlchemy<=1.4.41,>=1.4.17, but you have sqlalchemy 2.0.31 which is incompatible.\r\n",
      "zhipuai 2.0.1 requires pydantic>=2.5.2, but you have pydantic 1.10.17 which is incompatible.\u001B[0m\u001B[31m\r\n",
      "\u001B[0mSuccessfully installed pydantic-1.10.17\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pydantic==1.10.17\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T02:24:57.797023Z",
     "start_time": "2024-08-05T02:24:53.919306Z"
    }
   },
   "id": "cebfc731d0c0bf70",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4458caccbb05bc65"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
