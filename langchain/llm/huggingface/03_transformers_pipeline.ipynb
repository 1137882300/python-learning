{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "小白入门HuggingFace\n",
    "03 Transformers的神器 - Pipeline\n",
    "Pipeline 特性极度简化模型使用过程，使得从Hub上使用任何模型进行各种任务变得有趣而简单。即使没有特定模态经验，或者不熟悉模型背后逻辑的小白，仍然可以通过 Pipeline 进行推理!\n",
    "\n",
    "Transformers 为 Pipeline 特性提供了接口 pipeline() 函数。\n",
    "\n",
    "我们在本期会学习如何使用 pipeline() 函数。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2943ddd6e7d1a09d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 使用任意huggingface大模型的方式"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a2ade6ee4ac37a0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 文本摘要生成的例子\n",
    "每个任务类型都有相应的Pipeline类，但使用通用的 pipeline() 函数更简单，该函数会自动加载默认模型，或指定模型，以及能够对您的任务进行推理的预处理类。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51ed98d0887b47a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"summarization\")\n",
    "print(generator.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(model=\"knkarthick/MEETING_SUMMARY\")\n",
    "print(generator.__class__)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8c094d0d4cdd1a7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "London, the capital of England and the United Kingdom, is a 21st-century city with history stretching back to Roman times. At its centre stand the imposing Houses of Parliament, the iconic ‘Big Ben’ clock tower and Westminster Abbey, site of British monarch coronations. Across the Thames River, the London Eye observation wheel provides panoramic views of the South Bank cultural complex, and the entire city.\n",
    "\"\"\"\n",
    "generator(text)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ed0ae82b61b5d40"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 图像识别的例子"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ec6b79f277202a9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(model=\"google/vit-base-patch16-224\")\n",
    "print(classifier.__class__)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27e1cc04dec16daa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "image_url = \"https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png\"\n",
    "classifier(image_url)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fd3bb0eab37fbad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### pipeline函数的参数\n",
    "pipeline() 函数除了 task, model 参数，还支持一系列模型通用的参数，和模型特定的参数。\n",
    "\n",
    "介绍几个模型通用的重要的参数：\n",
    "\n",
    "device\n",
    "\n",
    "device参数接受以下几种可能的值:\n",
    "\n",
    "cpu：将模型加载到CPU上进行推理。\n",
    "cuda：将模型加载到第一块GPU进行推理，等同于'cuda:0'。\n",
    "cuda:X：将模型加载到编号为X的GPU上进行推理，X是GPU编号。\n",
    "mps：将模型加载到Mac OS上的Apple M1或M2芯片上利用Metal Performance Shaders (MPS) 进行推理。\n",
    "tpu：将模型加载到Tensor Processing Unit (TPU) 上进行推理,如Google Colab中的TPU。\n",
    "auto：自动选择一个可用的设备，会按优先级首先选择TPU，然后是GPU，最后是CPU。\n",
    "在huggingface transformers的pipeline函数中，device参数也可以设置为一个整数，比如0，是为了将模型加载到特定编号的 GPU 进行推理。\n",
    "\n",
    "batch_size\n",
    "\n",
    "默认情况下，pipeline并不会做批量推理（batch inference）。但是，pipeline函数依然提供了 batch_size 参数支持必要的batch inference。\n",
    "\n",
    "batch_size 参数会影响到:\n",
    "\n",
    "推理速度：增加batch_size通常可以提高GPU利用效率，加速推理速度。但若过大也会导致OOM。\n",
    "内存占用：较大的batch_size会占用更多GPU显存。\n",
    "推理效果：某些模型对batch_size比较敏感,大小不同会影响准确率。\n",
    "支持长度：一些模型对最大输入长度有限制,batch_size过大可能超出模型支持长度。\n",
    "输出：输出会是一个批量结果列表,如果只需要单条结果,需要索引获取。\n",
    "所以设置合适的batch_size需要综合考虑这些因素。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5977e06aef59fb5b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 模型特有的参数\n",
    "我们以文本分类为例，介绍模型特有参数的使用。\n",
    "\n",
    "文本分类的pipeline，由类 TextClassificationPipeline 实现，请参考文档 TextClassificationPipeline\n",
    "\n",
    "该类提供了模型特有的参数 return_all_scores，它用来标识是否返回所有预测分数或者只返回预测命中类别的分数。\n",
    "\n",
    "示例如下："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6834f4509abdd2b4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(model=\"ProsusAI/finbert\")\n",
    "print(classifier.__class__)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "879026f391451d2f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sentence = \"\"\"\n",
    "Hundreds of new North Sea oil and gas licences to boost British energy independence and grow the economy\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bec0fb31fd4b719"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "classifier(sentence)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d16e80454b8ac0fe"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "classifier(sentence, return_all_scores=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "426194ceed9ea64a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
