{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-14T01:31:07.688234Z",
     "start_time": "2024-08-14T01:31:07.298219Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.runnables.hub import HubRunnable\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 在运行时配置聊天模型字段（如温度）：\n",
    "model = (ChatOpenAI(temperature=0).configurable_fields(\n",
    "    temperature=ConfigurableField(\n",
    "        id=\"llm_temperature\",\n",
    "        name=\"LLM Temperature\",\n",
    "        description=\"The temperature of the LLM\",\n",
    "    )\n",
    "))\n",
    "\n",
    "model.invoke(\"pick a random number\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "930822fd1413b29b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 上面，我们将温度定义为可以在运行时设置的 ConfigurableField。为此，我们使用with_config方法，如下所示：\n",
    "model.with_config(configurable={\"llm_temperature\": 0.9}).invoke(\"pick a random number\")\n",
    "# 请注意，dict 中传递的 llm_temperature 条目与 ConfigurableField 的 id 具有相同的键。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fad93c6cb48b2b0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 我们也可以这样做，只影响链中的一个步骤：\n",
    "prompt = PromptTemplate.from_template(\"Pick a random number above {x}\")\n",
    "chain = prompt | model\n",
    "\n",
    "chain.invoke({\"x\": 0})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a94acb51d85f03f0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "chain.with_config(configurable={\"llm_temperature\": 0.9}).invoke({\"x\": 0})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6afcf562ba9c5a06"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "ChatPromptValue(messages=[HumanMessage(content=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: foo \\nContext: bar \\nAnswer:\")])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 HubRunnable\n",
    "# 这对于允许切换提示很有用\n",
    "\n",
    "prompt = HubRunnable(\"rlm/rag-prompt\").configurable_fields(\n",
    "    owner_repo_commit=ConfigurableField(\n",
    "        id=\"hub_commit\",\n",
    "        name=\"Hub Commit\",\n",
    "        description=\"The Hub commit to pull from\",\n",
    "    )\n",
    ")\n",
    "\n",
    "prompt.invoke({\"question\": \"foo\", \"context\": \"bar\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T01:31:13.701777Z",
     "start_time": "2024-08-14T01:31:12.116334Z"
    }
   },
   "id": "fa95154909bcd273",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "ChatPromptValue(messages=[HumanMessage(content=\"[INST]<<SYS>> You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.<</SYS>> \\nQuestion: foo \\nContext: bar \\nAnswer: [/INST]\")])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.with_config(configurable={\"hub_commit\": \"rlm/rag-prompt-llama\"}).invoke(\n",
    "    {\"question\": \"foo\", \"context\": \"bar\"}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T01:31:24.751734Z",
     "start_time": "2024-08-14T01:31:22.824942Z"
    }
   },
   "id": "51e038bbc0f2ba53",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 可配置的替代方案\n",
    "# Configurable Alternatives\n",
    "# configurable_alternatives（） 方法允许我们将链中的步骤与替代项交换。下面，我们将一种聊天模式换成另一种聊天模式：\n",
    "\n",
    "\n",
    "llm = ChatAnthropic(\n",
    "    model=\"claude-3-haiku-20240307\", temperature=0\n",
    ").configurable_alternatives(\n",
    "    # This gives this field an id\n",
    "    # When configuring the end runnable, we can then use this id to configure this field\n",
    "    ConfigurableField(id=\"llm\"),\n",
    "    # This sets a default_key.\n",
    "    # If we specify this key, the default LLM (ChatAnthropic initialized above) will be used\n",
    "    default_key=\"anthropic\",\n",
    "    # This adds a new option, with name `openai` that is equal to `ChatOpenAI()`\n",
    "    openai=ChatOpenAI(),\n",
    "    # This adds a new option, with name `gpt4` that is equal to `ChatOpenAI(model=\"gpt-4\")`\n",
    "    gpt4=ChatOpenAI(model=\"gpt-4\"),\n",
    "    # You can add more configuration options here\n",
    ")\n",
    "prompt = PromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "chain = prompt | llm\n",
    "\n",
    "# By default it will call Anthropic\n",
    "chain.invoke({\"topic\": \"bears\"})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d91f29f76d6bc7c9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# We can use `.with_config(configurable={\"llm\": \"openai\"})` to specify an llm to use\n",
    "chain.with_config(configurable={\"llm\": \"openai\"}).invoke({\"topic\": \"bears\"})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cba38660062d0da"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# If we use the `default_key` then it uses the default\n",
    "chain.with_config(configurable={\"llm\": \"anthropic\"}).invoke({\"topic\": \"bears\"})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "660c6d4b51118dd8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# With Prompts\n",
    "# 我们可以做类似的事情，但在提示之间交替\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-3-haiku-20240307\", temperature=0)\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Tell me a joke about {topic}\"\n",
    ").configurable_alternatives(\n",
    "    # This gives this field an id\n",
    "    # When configuring the end runnable, we can then use this id to configure this field\n",
    "    ConfigurableField(id=\"prompt\"),\n",
    "    # This sets a default_key.\n",
    "    # If we specify this key, the default prompt (asking for a joke, as initialized above) will be used\n",
    "    default_key=\"joke\",\n",
    "    # This adds a new option, with name `poem`\n",
    "    poem=PromptTemplate.from_template(\"Write a short poem about {topic}\"),\n",
    "    # You can add more configuration options here\n",
    ")\n",
    "chain = prompt | llm\n",
    "\n",
    "# By default it will write a joke\n",
    "chain.invoke({\"topic\": \"bears\"})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "509044a9113f32f8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# We can configure it write a poem\n",
    "chain.with_config(configurable={\"prompt\": \"poem\"}).invoke({\"topic\": \"bears\"})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf09c210ceaf9eea"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# With Prompts and LLMs\n",
    "# 带有提示和LLMs\n",
    "# 我们还可以配置多个东西！下面是一个使用提示和 LLMs执行此操作的示例。\n",
    "\n",
    "llm = ChatAnthropic(\n",
    "    model=\"claude-3-haiku-20240307\", temperature=0\n",
    ").configurable_alternatives(\n",
    "    # This gives this field an id\n",
    "    # When configuring the end runnable, we can then use this id to configure this field\n",
    "    ConfigurableField(id=\"llm\"),\n",
    "    # This sets a default_key.\n",
    "    # If we specify this key, the default LLM (ChatAnthropic initialized above) will be used\n",
    "    default_key=\"anthropic\",\n",
    "    # This adds a new option, with name `openai` that is equal to `ChatOpenAI()`\n",
    "    openai=ChatOpenAI(),\n",
    "    # This adds a new option, with name `gpt4` that is equal to `ChatOpenAI(model=\"gpt-4\")`\n",
    "    gpt4=ChatOpenAI(model=\"gpt-4\"),\n",
    "    # You can add more configuration options here\n",
    ")\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Tell me a joke about {topic}\"\n",
    ").configurable_alternatives(\n",
    "    # This gives this field an id\n",
    "    # When configuring the end runnable, we can then use this id to configure this field\n",
    "    ConfigurableField(id=\"prompt\"),\n",
    "    # This sets a default_key.\n",
    "    # If we specify this key, the default prompt (asking for a joke, as initialized above) will be used\n",
    "    default_key=\"joke\",\n",
    "    # This adds a new option, with name `poem`\n",
    "    poem=PromptTemplate.from_template(\"Write a short poem about {topic}\"),\n",
    "    # You can add more configuration options here\n",
    ")\n",
    "chain = prompt | llm\n",
    "\n",
    "# We can configure it write a poem with OpenAI\n",
    "chain.with_config(configurable={\"prompt\": \"poem\", \"llm\": \"openai\"}).invoke(\n",
    "    {\"topic\": \"bears\"}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "619f7e57c5732edd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# We can always just configure only one if we want\n",
    "chain.with_config(configurable={\"llm\": \"openai\"}).invoke({\"topic\": \"bears\"})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b1a86855043bac1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Saving configurations\n",
    "# 保存配置\n",
    "# 我们还可以轻松地将配置的链保存为自己的对象\n",
    "\n",
    "openai_joke = chain.with_config(configurable={\"llm\": \"openai\"})\n",
    "\n",
    "openai_joke.invoke({\"topic\": \"bears\"})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2de743ae688448b8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
