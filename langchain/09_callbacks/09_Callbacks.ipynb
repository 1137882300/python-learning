{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a709c4bbf626fd2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T08:06:03.209008Z",
     "start_time": "2024-06-28T08:06:02.656950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8483c3ec7a0cbc54a8d660b5b9002b04\n",
      "Gcllof8ze6dgtcqFI5FQZ2SD_5tfCD4Db7NuS6jn\n",
      "sk-01c5003340c3453b934052d737d45e01\n",
      "sk-UGVpjuTwo2Q8pewoqUDfckw1A0pbSDli9ElFMeS9WareKknG\n",
      "https://api.moonshot.cn/v1/\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "from langchain_community.llms.cloudflare_workersai import CloudflareWorkersAI\n",
    "from langchain_community.llms.tongyi import Tongyi\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "account_id = os.getenv('CF_ACCOUNT_ID')\n",
    "api_token = os.getenv('CF_API_TOKEN')\n",
    "print(account_id)\n",
    "print(api_token)\n",
    "\n",
    "# CloudflareWorkersAI\n",
    "model = '@cf/meta/llama-3-8b-instruct'\n",
    "cf_llm = CloudflareWorkersAI(\n",
    "    account_id=account_id,\n",
    "    api_token=api_token,\n",
    "    model=model\n",
    ")\n",
    "\n",
    "DASHSCOPE_API_KEY = os.getenv('DASHSCOPE_API_KEY')\n",
    "print(DASHSCOPE_API_KEY)\n",
    "\n",
    "# qwen\n",
    "qw_llm = Tongyi(\n",
    "    model='qwen2-1.5b-instruct'\n",
    ")\n",
    "\n",
    "# qwen 兼容 openai的接口\n",
    "qw_llm_openai = ChatOpenAI(\n",
    "    openai_api_base='https://dashscope.aliyuncs.com/compatible-mode/v1',\n",
    "    openai_api_key=DASHSCOPE_API_KEY,\n",
    "    model_name=\"qwen2-1.5b-instruct\",\n",
    "    temperature=0.7,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "base_url = os.getenv('OPENAI_API_BASE')\n",
    "print(api_key)\n",
    "print(base_url)\n",
    "\n",
    "# openai/moonshot\n",
    "ms_llm = ChatOpenAI(\n",
    "    openai_api_base=base_url,\n",
    "    openai_api_key=api_key,\n",
    "    model_name=\"moonshot-v1-8k\",\n",
    "    temperature=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'langchain_core.callbacks.stdout.StdOutCallbackHandler'>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m prompt \u001B[38;5;241m=\u001B[39m PromptTemplate\u001B[38;5;241m.\u001B[39mfrom_template(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWho is \u001B[39m\u001B[38;5;132;01m{name}\u001B[39;00m\u001B[38;5;124m?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# chain = LLMChain(llm=qw_llm_openai, prompt=prompt, callbacks=[handler])\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m chain \u001B[38;5;241m=\u001B[39m \u001B[43mprompt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m|\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mqw_llm_openai\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m|\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mhandler\u001B[49m\n\u001B[1;32m      5\u001B[0m chain\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSuper Mario\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:2446\u001B[0m, in \u001B[0;36mRunnableSequence.__or__\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m   2432\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m RunnableSequence(\n\u001B[1;32m   2433\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfirst,\n\u001B[1;32m   2434\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmiddle,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2439\u001B[0m         name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname \u001B[38;5;129;01mor\u001B[39;00m other\u001B[38;5;241m.\u001B[39mname,\n\u001B[1;32m   2440\u001B[0m     )\n\u001B[1;32m   2441\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2442\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m RunnableSequence(\n\u001B[1;32m   2443\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfirst,\n\u001B[1;32m   2444\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmiddle,\n\u001B[1;32m   2445\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlast,\n\u001B[0;32m-> 2446\u001B[0m         \u001B[43mcoerce_to_runnable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m   2447\u001B[0m         name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname,\n\u001B[1;32m   2448\u001B[0m     )\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:5031\u001B[0m, in \u001B[0;36mcoerce_to_runnable\u001B[0;34m(thing)\u001B[0m\n\u001B[1;32m   5029\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(Runnable[Input, Output], RunnableParallel(thing))\n\u001B[1;32m   5030\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 5031\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m   5032\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected a Runnable, callable or dict.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   5033\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInstead got an unsupported type: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(thing)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   5034\u001B[0m     )\n",
      "\u001B[0;31mTypeError\u001B[0m: Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'langchain_core.callbacks.stdout.StdOutCallbackHandler'>"
     ]
    }
   ],
   "source": [
    "# 内置回调处理器 StdOutCallbackHandler\n",
    "\n",
    "handler = StdOutCallbackHandler()\n",
    "prompt = PromptTemplate.from_template(\"Who is {name}?\")\n",
    "chain = LLMChain(llm=qw_llm_openai, prompt=prompt, callbacks=[handler])\n",
    "# chain = prompt | qw_llm_openai | lambda x: callbacks=[handler]\n",
    "chain.invoke(\"Super Mario\")"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-28T08:11:45.964974Z",
     "start_time": "2024-06-28T08:11:45.960058Z"
    }
   },
   "id": "initial_id",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 自定义回调处理器\n",
    "# 我们来实现一个处理器，统计每次 LLM 交互的处理时间。\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "import time\n",
    "\n",
    "\n",
    "class TimerHandler(BaseCallbackHandler):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.previous_ms = None\n",
    "        self.durations = []\n",
    "\n",
    "    def current_ms(self):\n",
    "        return int(time.time() * 1000 + time.perf_counter() % 1 * 1000)\n",
    "\n",
    "    def on_chain_start(self, serialized, inputs, **kwargs) -> None:\n",
    "        self.previous_ms = self.current_ms()\n",
    "\n",
    "    def on_chain_end(self, outputs, **kwargs) -> None:\n",
    "        if self.previous_ms:\n",
    "            duration = self.current_ms() - self.previous_ms\n",
    "            self.durations.append(duration)\n",
    "\n",
    "    def on_llm_start(self, serialized, prompts, **kwargs) -> None:\n",
    "        self.previous_ms = self.current_ms()\n",
    "\n",
    "    def on_llm_end(self, response, **kwargs) -> None:\n",
    "        if self.previous_ms:\n",
    "            duration = self.current_ms() - self.previous_ms\n",
    "            self.durations.append(duration)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T08:14:07.518106Z",
     "start_time": "2024-06-28T08:14:07.513186Z"
    }
   },
   "id": "3799c3b5ec27f86a",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'color_name': 'blue', 'text': 'The hexadecimal (HEX) code for the color blue is #008000.'}\n",
      "{'color_name': 'purple', 'text': 'The hexadecimal (HEX) code for purple is #800080.'}\n"
     ]
    },
    {
     "data": {
      "text/plain": "[1381, -11]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timerHandler = TimerHandler()\n",
    "prompt = PromptTemplate.from_template(\"What is the HEX code of color {color_name}?\")\n",
    "chain = LLMChain(llm=qw_llm_openai, prompt=prompt, callbacks=[timerHandler])\n",
    "response = chain.invoke(\"blue\")\n",
    "print(response)\n",
    "response = chain.invoke(\"purple\")\n",
    "print(response)\n",
    "\n",
    "timerHandler.durations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T08:14:31.583114Z",
     "start_time": "2024-06-28T08:14:30.393177Z"
    }
   },
   "id": "7c67e4036d7db8df",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The hexadecimal (HEX) code for black is #000000.' response_metadata={'finish_reason': 'stop'} id='run-0f76c9cf-9d6e-4d32-847f-18353df050f9-0'\n"
     ]
    },
    {
     "data": {
      "text/plain": "[503]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 与 callbacks\n",
    "# callbacks 可以在构造函数中指定，也可以在执行期间的函数调用中指定。\n",
    "timerHandler = TimerHandler()\n",
    "qw_llm_openai_2 = ChatOpenAI(\n",
    "    openai_api_base='https://dashscope.aliyuncs.com/compatible-mode/v1',\n",
    "    openai_api_key=DASHSCOPE_API_KEY,\n",
    "    model_name=\"qwen2-1.5b-instruct\",\n",
    "    temperature=0.7,\n",
    "    streaming=True,\n",
    "    callbacks=[timerHandler]\n",
    ")\n",
    "response = qw_llm_openai_2.invoke(\"What is the HEX code of color BLACK?\")\n",
    "print(response)\n",
    "\n",
    "timerHandler.durations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T08:15:53.793951Z",
     "start_time": "2024-06-28T08:15:53.001294Z"
    }
   },
   "id": "32f1a5a22e5b61b0",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The hexadecimal (HEX) code for black is #000000.' response_metadata={'finish_reason': 'stop'} id='run-784923c2-79ec-4311-9e10-e8c18b7aa72c-0'\n"
     ]
    },
    {
     "data": {
      "text/plain": "[503, 5511]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 也可以这样传参\n",
    "response = qw_llm_openai_2.invoke(\"What is the HEX code of color BLACK?\",\n",
    "                                  config={\"callbacks\": [timerHandler]})\n",
    "print(response)\n",
    "\n",
    "timerHandler.durations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T08:20:14.921575Z",
     "start_time": "2024-06-28T08:20:09.157794Z"
    }
   },
   "id": "813cb611f7508716",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "329aa59524d5236f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
