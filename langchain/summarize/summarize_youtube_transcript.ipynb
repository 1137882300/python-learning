{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-30T14:37:58.588489Z",
     "start_time": "2024-06-30T14:37:58.538829Z"
    }
   },
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api.formatters import TextFormatter"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TranscriptsDisabled",
     "evalue": "\nCould not retrieve a transcript for the video https://www.youtube.com/watch?v=D_TyrPyGXyM&t=624s! This is most likely caused by:\n\nSubtitles are disabled for this video\n\nIf you are sure that the described cause is not responsible for this error and that a transcript should be retrievable, please create an issue at https://github.com/jdepoix/youtube-transcript-api/issues. Please add which version of youtube_transcript_api you are using and provide the information needed to replicate the error. Also make sure that there are no open issues which already describe your problem!",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTranscriptsDisabled\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# proxies = {'https': 'https://crab233.cloudns.biz/proxy/'}\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m transcript_list \u001B[38;5;241m=\u001B[39m \u001B[43mYouTubeTranscriptApi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlist_transcripts\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mD_TyrPyGXyM&t=624s\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(transcript_list)\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/youtube_transcript_api/_api.py:71\u001B[0m, in \u001B[0;36mYouTubeTranscriptApi.list_transcripts\u001B[0;34m(cls, video_id, proxies, cookies)\u001B[0m\n\u001B[1;32m     69\u001B[0m     http_client\u001B[38;5;241m.\u001B[39mcookies \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_load_cookies(cookies, video_id)\n\u001B[1;32m     70\u001B[0m http_client\u001B[38;5;241m.\u001B[39mproxies \u001B[38;5;241m=\u001B[39m proxies \u001B[38;5;28;01mif\u001B[39;00m proxies \u001B[38;5;28;01melse\u001B[39;00m {}\n\u001B[0;32m---> 71\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mTranscriptListFetcher\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhttp_client\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvideo_id\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/youtube_transcript_api/_transcripts.py:48\u001B[0m, in \u001B[0;36mTranscriptListFetcher.fetch\u001B[0;34m(self, video_id)\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, video_id):\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m TranscriptList\u001B[38;5;241m.\u001B[39mbuild(\n\u001B[1;32m     46\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_http_client,\n\u001B[1;32m     47\u001B[0m         video_id,\n\u001B[0;32m---> 48\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_extract_captions_json\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fetch_video_html\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvideo_id\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvideo_id\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m     49\u001B[0m     )\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/youtube_transcript_api/_transcripts.py:62\u001B[0m, in \u001B[0;36mTranscriptListFetcher._extract_captions_json\u001B[0;34m(self, html, video_id)\u001B[0m\n\u001B[1;32m     59\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplayabilityStatus\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m html:\n\u001B[1;32m     60\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m VideoUnavailable(video_id)\n\u001B[0;32m---> 62\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m TranscriptsDisabled(video_id)\n\u001B[1;32m     64\u001B[0m captions_json \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(\n\u001B[1;32m     65\u001B[0m     splitted_html[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvideoDetails\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     66\u001B[0m )\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mplayerCaptionsTracklistRenderer\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m captions_json \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mTranscriptsDisabled\u001B[0m: \nCould not retrieve a transcript for the video https://www.youtube.com/watch?v=D_TyrPyGXyM&t=624s! This is most likely caused by:\n\nSubtitles are disabled for this video\n\nIf you are sure that the described cause is not responsible for this error and that a transcript should be retrievable, please create an issue at https://github.com/jdepoix/youtube-transcript-api/issues. Please add which version of youtube_transcript_api you are using and provide the information needed to replicate the error. Also make sure that there are no open issues which already describe your problem!"
     ]
    }
   ],
   "source": [
    "# proxies = {'https': 'https://crab233.cloudns.biz/proxy/'}\n",
    "transcript_list = YouTubeTranscriptApi.list_transcripts('D_TyrPyGXyM&t=624s')\n",
    "print(transcript_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T14:39:31.850729Z",
     "start_time": "2024-06-30T14:39:30.000374Z"
    }
   },
   "id": "a7214455a6a682ab",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# trz7g-wilxs = \"5 RULES FOR THE REST OF YOUR LIFE\" | Matthew McConaughey MOTIVATIONAL SPEECH\n",
    "# UF9Iqmg94tk = \"Consistent Hashing | Algorithms You Should Know #1\"\n",
    "transcript = YouTubeTranscriptApi.get_transcript('UF9Iqmg94tk', languages=['en-US'])\n",
    "# transcript = YouTubeTranscriptApi.get_transcript('XPMysVisyWE')\n",
    "formatter = TextFormatter()\n",
    "text_formatted = formatter.format_transcript(transcript)\n",
    "with open('transcript.txt', 'w', encoding='utf-8') as text_file:\n",
    "    text_file.write(text_formatted)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T14:40:05.933219Z",
     "start_time": "2024-06-30T14:40:01.642522Z"
    }
   },
   "id": "ca96aaabf0b3eaaa",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do DynamoDB, Apache Cassandra, Discord, and \r\n",
      "Akamai CDN have in common? They all use consistent  \r\n",
      "hashing. Now, what is consistent hashing? Why do all \r\n",
      "the cool kids use it? In this video, we'll learn  \r\n",
      "all about it. Let's dive right in. In a large scale \r\n",
      "distributed system, data does not fit on a single  \r\n",
      "server. They are distributed across many machines. \r\n",
      "This is called horizontal scaling. To build such  \r\n",
      "a system with predictable performance. it is \r\n",
      "important to distribute the data evenly across  \r\n",
      "those servers. A common method to distribute \r\n",
      "data as evenly as possible among servers is  \r\n",
      "simple hashing. This is how it works. First, for each \r\n",
      "object, we hash its key with a hashing function  \r\n",
      "like MD5 or MurmurHash. This maps the object \r\n",
      "key to a known range of numerical values.  \r\n",
      "A good hashing function distributes the \r\n",
      "hashes evenly across the entire range.  \r\n",
      "Second, we perform the modulo operation on the \r\n",
      "hash against the number of servers. This determines  \r\n",
      "which servers the object belongs to. As long \r\n",
      "as the number of servers stays the same,  \r\n",
      "an object key will always map to the same server. \r\n",
      "Here's a concrete example. We have four servers  \r\n",
      "with eight string keys with simple hashing \r\n",
      "this is how we distribute the eight string  \r\n",
      "keys among the four servers. Now, this approach \r\n",
      "works well when the size of the cluster is fixed,  \r\n",
      "and the data distribution is even. But what happens \r\n",
      "when new servers get added to meet new demand  \r\n",
      "or when existing servers get removed? \r\n",
      "Back to our example. If server 1 goes down,  \r\n",
      "the size of the cluster is now three. Even though \r\n",
      "the hashes for the object keys stay the same,  \r\n",
      "we are now applying the modulo operation to a \r\n",
      "different set of n. In this case, it is now three.  \r\n",
      "The impact is pretty drastic. Most of the keys get \r\n",
      "redistributed. This affects almost all objects, it's  \r\n",
      "not just the objects originally stored in the \r\n",
      "server that is now offline. This triggers a storm  \r\n",
      "of misses and lots of objects to be moved. For \r\n",
      "situations where servers constantly come and go,  \r\n",
      "this design is untenable. Consistent hashing is \r\n",
      "an effective technique to mitigate this issue.  \r\n",
      "The goal of consistent hashing is this. We want \r\n",
      "almost all objects to stay assigned to the same  \r\n",
      "server even as the number of servers changes. \r\n",
      "Here is the core insight of consistent hashing.  \r\n",
      "In addition to hashing the object keys like before, \r\n",
      "we also hash the server names. The objects and  \r\n",
      "servers are hashed with the same hashing function \r\n",
      "to the same range of values. In our example we have  \r\n",
      "a range of x0 to xn. This range is called a hash \r\n",
      "space. Next, we connect both ends of the hash space  \r\n",
      "to form a ring. This is a hash ring. Using a hashing \r\n",
      "function we hash each server by its name or ip  \r\n",
      "address, and place the server onto the ring. Here, we \r\n",
      "place our four servers onto the ring. Next, we hash  \r\n",
      "each object by its key with the same hashing \r\n",
      "function. Unlike simple hashing where we perform  \r\n",
      "a modulo operation on the hash, here we use the \r\n",
      "hash directly to map the object key onto the ring.  \r\n",
      "Here is what it would look like for our four \r\n",
      "objects. To locate the server for a particular  \r\n",
      "object, we go clockwise from the location of the \r\n",
      "object key on the ring until a server is found.  \r\n",
      "Continue with our example, key 0 is on server 0, \r\n",
      "and key 1 is on server 1. Now, let's take a look at  \r\n",
      "what happens when we add a server. Here we insert \r\n",
      "a new server s4 to the left of s0 on the ring.  \r\n",
      "Note that only k0 needs to be moved from s0 to \r\n",
      "s4. This is because s4 is the first server k0  \r\n",
      "encounters by going clockwise from k0's position \r\n",
      "on the ring. Keys k1, k2 ,and k3 are not affected.  \r\n",
      "With simple hashing, when a new server is added \r\n",
      "almost all the keys need to be remapped. With  \r\n",
      "consistent hashing, adding a new server only \r\n",
      "requires redistribution of a fraction of the keys.  \r\n",
      "Let's walk through a quick example of removing \r\n",
      "a server. When s1 is removed, only k1 needs to be  \r\n",
      "remapped to s2. The rest of the keys are unaffected. \r\n",
      "Let's recap. What have we learned so far. One,  \r\n",
      "we map both servers and objects onto the hash \r\n",
      "ring using a uniformly distributed hash function.  \r\n",
      "Two, to locate a server for an object, we go \r\n",
      "clockwise on the ring from the object's position  \r\n",
      "until a server is found. Now, let's consider \r\n",
      "a potential issue with this design.  \r\n",
      "The distribution of the objects in the \r\n",
      "servers on the ring is likely to be uneven.  \r\n",
      "Conceptually, we pick n random points on the ring, \r\n",
      "we are very unlikely to get a perfect partition of  \r\n",
      "the ring into equally sized segments. For example ,\r\n",
      "if servers are mapped on the ring like this,  \r\n",
      "most of the objects are stored in s2, with s1 \r\n",
      "and s3 storing no data. This problem gets worse  \r\n",
      "if servers come and go frequently. In our example, \r\n",
      "even if the servers were originally evenly spaced,  \r\n",
      "if s1 is removed, the segment for s2 is now \r\n",
      "twice as large as the ones for s0 and s3.  \r\n",
      "Virtual nodes are used to fix this problem. The \r\n",
      "idea is to have each server appear at multiple  \r\n",
      "locations on the ring. Each location is a virtual \r\n",
      "node representing a server. In this hash ring, we  \r\n",
      "have two servers, with each having three virtual \r\n",
      "nodes. Instead of having s0 and s1, we now have  \r\n",
      "s0_0, s0_1, and s0_2 to represent server 0, and s1_0 \r\n",
      "s1_1, and s1_2 to represent server 1 on the ring.  \r\n",
      "With virtual nodes, each server handles multiple \r\n",
      "segments on the ring. In our example, the segments  \r\n",
      "labeled s0 are managed by server 0, and \r\n",
      "those labeled s1 are handled by server 1.  \r\n",
      "In real world systems, the number of \r\n",
      "virtual nodes is much larger than  \r\n",
      "three. As the number of virtual nodes increases, \r\n",
      "the distribution of objects becomes more balanced.  \r\n",
      "Having more virtual nodes means taking more space \r\n",
      "to store the metadata about the virtual nodes.  \r\n",
      "This is a trade-off, and we can tune the number \r\n",
      "of virtual nodes to fit our system requirements. \r\n",
      "Let's see how consistent hashing is used in \r\n",
      "the real world. Some popular NoSQL databases  \r\n",
      "like Amazon DynamoDB and Apache Cassandra use \r\n",
      "consistent hashing, where it is used for data  \r\n",
      "partitioning. It helps these databases minimize \r\n",
      "data movement during rebalancing. Content delivery  \r\n",
      "networks like Akamai use consistent hashing to \r\n",
      "help distribute web contents evenly among the  \r\n",
      "edge servers. Load balancers like Google Load \r\n",
      "Balancer use consistent hashing to distribute  \r\n",
      "persistent connections evenly across backend \r\n",
      "servers. This limits the number of connections  \r\n",
      "that need to be re-established when a backend \r\n",
      "server goes down. That's it for consistent hashing.  \r\n",
      "If you would like to learn more about system \r\n",
      "design, check out our books and weekly newsletters.  \r\n",
      "Please subscribe if you learned something new. \r\n",
      "Thank you so much, and we'll see you next time."
     ]
    }
   ],
   "source": [
    "%cat transcript.txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:45:23.930866Z",
     "start_time": "2024-06-28T03:45:23.795760Z"
    }
   },
   "id": "523eeff2691334a9",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"./transcript.txt\")\n",
    "docs = loader.load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:45:57.476444Z",
     "start_time": "2024-06-28T03:45:57.321070Z"
    }
   },
   "id": "112eb271bb206931",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document(s) in your data\n",
      "There are 6768 characters in your document\n"
     ]
    }
   ],
   "source": [
    "print(f'You have {len(docs)} document(s) in your data')\n",
    "print(f'There are {len(docs[0].page_content)} characters in your document')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:45:58.961806Z",
     "start_time": "2024-06-28T03:45:58.958991Z"
    }
   },
   "id": "a96563523014d54c",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "split_docs = text_splitter.split_documents(docs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:46:11.702089Z",
     "start_time": "2024-06-28T03:46:11.686582Z"
    }
   },
   "id": "a141a8f19dff424a",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 7 split document(s)\n"
     ]
    }
   ],
   "source": [
    "print(f'You have {len(split_docs)} split document(s)')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:46:16.096549Z",
     "start_time": "2024-06-28T03:46:16.093517Z"
    }
   },
   "id": "6b46495f5b881ef0",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8483c3ec7a0cbc54a8d660b5b9002b04\n",
      "Gcllof8ze6dgtcqFI5FQZ2SD_5tfCD4Db7NuS6jn\n",
      "sk-01c5003340c3453b934052d737d45e01\n",
      "sk-UGVpjuTwo2Q8pewoqUDfckw1A0pbSDli9ElFMeS9WareKknG\n",
      "https://api.moonshot.cn/v1/\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_community.llms.cloudflare_workersai import CloudflareWorkersAI\n",
    "from langchain_community.llms.tongyi import Tongyi\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "account_id = os.getenv('CF_ACCOUNT_ID')\n",
    "api_token = os.getenv('CF_API_TOKEN')\n",
    "print(account_id)\n",
    "print(api_token)\n",
    "\n",
    "# CloudflareWorkersAI\n",
    "model = '@cf/meta/llama-3-8b-instruct'\n",
    "cf_llm = CloudflareWorkersAI(\n",
    "    account_id=account_id,\n",
    "    api_token=api_token,\n",
    "    model=model\n",
    ")\n",
    "\n",
    "DASHSCOPE_API_KEY = os.getenv('DASHSCOPE_API_KEY')\n",
    "print(DASHSCOPE_API_KEY)\n",
    "\n",
    "# qwen\n",
    "qw_llm = Tongyi(\n",
    "    model='qwen2-1.5b-instruct'\n",
    ")\n",
    "\n",
    "# qwen 兼容 openai的接口\n",
    "qw_llm_openai = ChatOpenAI(\n",
    "    openai_api_base='https://dashscope.aliyuncs.com/compatible-mode/v1',\n",
    "    openai_api_key=DASHSCOPE_API_KEY,\n",
    "    model_name=\"qwen2-1.5b-instruct\",\n",
    "    temperature=0,\n",
    "    streaming=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "base_url = os.getenv('OPENAI_API_BASE')\n",
    "print(api_key)\n",
    "print(base_url)\n",
    "\n",
    "# openai/moonshot\n",
    "ms_llm = ChatOpenAI(\n",
    "    openai_api_base=base_url,\n",
    "    openai_api_key=api_key,\n",
    "    model_name=\"moonshot-v1-8k\",\n",
    "    temperature=0.7,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:46:49.018579Z",
     "start_time": "2024-06-28T03:46:48.508614Z"
    }
   },
   "id": "fec1c4060b4c5b17",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "chain = load_summarize_chain(qw_llm_openai, chain_type=\"map_reduce\", verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:46:53.373345Z",
     "start_time": "2024-06-28T03:46:53.277401Z"
    }
   },
   "id": "cb7a1d3e5b980ba8",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_docs = split_docs[:2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:46:57.689470Z",
     "start_time": "2024-06-28T03:46:57.683092Z"
    }
   },
   "id": "b34e36768bdb42c4",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MapReduceDocumentsChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"What do DynamoDB, Apache Cassandra, Discord, and \n",
      "Akamai CDN have in common? They all use consistent  \n",
      "hashing. Now, what is consistent hashing? Why do all \n",
      "the cool kids use it? In this video, we'll learn  \n",
      "all about it. Let's dive right in. In a large scale \n",
      "distributed system, data does not fit on a single  \n",
      "server. They are distributed across many machines. \n",
      "This is called horizontal scaling. To build such  \n",
      "a system with predictable performance. it is \n",
      "important to distribute the data evenly across  \n",
      "those servers. A common method to distribute \n",
      "data as evenly as possible among servers is  \n",
      "simple hashing. This is how it works. First, for each \n",
      "object, we hash its key with a hashing function  \n",
      "like MD5 or MurmurHash. This maps the object \n",
      "key to a known range of numerical values.  \n",
      "A good hashing function distributes the \n",
      "hashes evenly across the entire range.  \n",
      "Second, we perform the modulo operation on the \n",
      "hash against the number of servers. This determines\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"which servers the object belongs to. As long \n",
      "as the number of servers stays the same,  \n",
      "an object key will always map to the same server. \n",
      "Here's a concrete example. We have four servers  \n",
      "with eight string keys with simple hashing \n",
      "this is how we distribute the eight string  \n",
      "keys among the four servers. Now, this approach \n",
      "works well when the size of the cluster is fixed,  \n",
      "and the data distribution is even. But what happens \n",
      "when new servers get added to meet new demand  \n",
      "or when existing servers get removed? \n",
      "Back to our example. If server 1 goes down,  \n",
      "the size of the cluster is now three. Even though \n",
      "the hashes for the object keys stay the same,  \n",
      "we are now applying the modulo operation to a \n",
      "different set of n. In this case, it is now three.  \n",
      "The impact is pretty drastic. Most of the keys get \n",
      "redistributed. This affects almost all objects, it's  \n",
      "not just the objects originally stored in the \n",
      "server that is now offline. This triggers a storm\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"Consistent hashing is a method used to distribute data evenly across multiple servers in a distributed system. It involves hashing the keys of objects with a hashing function like MD5 or MurmurHash, which then maps them to a known range of numerical values. The result is a set of hashed keys that are evenly distributed across the range. This allows for predictable performance and ensures that data is evenly distributed across servers, even when the number of servers changes. Consistent hashing is commonly used in systems such as DynamoDB, Apache Cassandra, Discord, and Akamai CDN.\n",
      "\n",
      "When adding or removing servers from a cluster, the number of servers changes and so do the hash values of the object keys. This leads to the loss of some object keys and redistribution of others, causing a storm. The summary highlights the need for an efficient and scalable solution to handle such scenarios while maintaining the integrity of the distributed object storage system.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "Total Tokens: 0\n",
      "Prompt Tokens: 0\n",
      "Completion Tokens: 0\n",
      "Successful Requests: 0\n",
      "Total Cost (USD): $0.0\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    chain.invoke(input_docs)\n",
    "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Successful Requests: {cb.successful_requests}\")\n",
    "    print(f\"Total Cost (USD): ${cb.total_cost}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:47:24.834895Z",
     "start_time": "2024-06-28T03:47:22.073950Z"
    }
   },
   "id": "1249476a90de2a18",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e18245656d3ae6a4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
