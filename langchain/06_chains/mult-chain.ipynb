{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# hyde_chain = hyde_prompt | model | StrOutputParser()\n",
    "\n",
    "# # RAG chain\n",
    "# chain = (\n",
    "#     RunnableParallel 会并行处理\n",
    "#     RunnableParallel(\n",
    "#         {\n",
    "#             # 生成一个假设的文档，然后将其传递给检索器\n",
    "#             \"context\": hyde_chain | retriever,\n",
    "#             \"question\": lambda x: x[\"question\"],\n",
    "#         }\n",
    "#     )\n",
    "#     | prompt\n",
    "#     | model\n",
    "#     | StrOutputParser()\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f19b60178d9fb3a8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 想加到chain里的数据，使用 RunnableLambda 来包装 ❤️\n",
    "\n",
    "# chain = (\n",
    "#         {\n",
    "#             \"context\": retriever | RunnableLambda(get_resized_images),\n",
    "#             \"question\": RunnablePassthrough(),\n",
    "#         }\n",
    "#         | RunnableLambda(img_prompt_func)\n",
    "#         | model\n",
    "#         | StrOutputParser()\n",
    "# )\n",
    "# \n",
    "# def get_resized_images(docs):\n",
    "#     \"\"\"\n",
    "#     Resize images from base64-encoded strings.\n",
    "# \n",
    "#     :param docs: A list of base64-encoded image to be resized.\n",
    "#     :return: Dict containing a list of resized base64-encoded strings.\n",
    "#     \"\"\"\n",
    "#     b64_images = []\n",
    "#     for doc in docs:\n",
    "#         if isinstance(doc, Document):\n",
    "#             doc = doc.page_content\n",
    "#         resized_image = resize_base64_image(doc, size=(1280, 720))\n",
    "#         b64_images.append(resized_image)\n",
    "#     return {\"images\": b64_images}\n",
    "# \n",
    "# def img_prompt_func(data_dict, num_images=2):\n",
    "#     \"\"\"\n",
    "#     GPT-4V prompt for image analysis.\n",
    "# \n",
    "#     :param data_dict: A dict with images and a user-provided question.\n",
    "#     :param num_images: Number of images to include in the prompt.\n",
    "#     :return: A list containing message objects for each image and the text prompt.\n",
    "#     \"\"\"\n",
    "#     messages = []\n",
    "#     if data_dict[\"context\"][\"images\"]:\n",
    "#         for image in data_dict[\"context\"][\"images\"][:num_images]:\n",
    "#             image_message = {\n",
    "#                 \"type\": \"image_url\",\n",
    "#                 \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"},\n",
    "#             }\n",
    "#             messages.append(image_message)\n",
    "#     text_message = {\n",
    "#         \"type\": \"text\",\n",
    "#         \"text\": (\n",
    "#             \"You are an analyst tasked with answering questions about visual content.\\n\"\n",
    "#             \"You will be give a set of image(s) from a slide deck / presentation.\\n\"\n",
    "#             \"Use this information to answer the user question. \\n\"\n",
    "#             f\"User-provided question: {data_dict['question']}\\n\\n\"\n",
    "#         ),\n",
    "#     }\n",
    "#     messages.append(text_message)\n",
    "#     return [HumanMessage(content=messages)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4955a2b626ee55f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
