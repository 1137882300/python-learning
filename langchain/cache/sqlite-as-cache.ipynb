{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!rm -f .cache.db"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T07:29:11.100305Z",
     "start_time": "2024-07-08T07:29:10.974339Z"
    }
   },
   "id": "629a9b1d17bf1475",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 基本配置\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "cf_llm_openai = ChatOpenAI(\n",
    "    openai_api_base=os.getenv('CF_API_BASE'),\n",
    "    openai_api_key=os.getenv('CF_API_TOKEN'),\n",
    "    model_name=\"@cf/meta/llama-3-8b-instruct\",\n",
    "    temperature=0,\n",
    "    streaming=True,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T07:30:14.064573Z",
     "start_time": "2024-07-08T07:30:13.541885Z"
    }
   },
   "id": "334ecdba6238efbc",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.cache import SQLiteCache\n",
    "\n",
    "langchain.llm_cache = SQLiteCache(database_path=\".cache.db\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T07:30:15.788536Z",
     "start_time": "2024-07-08T07:30:15.580076Z"
    }
   },
   "id": "3f2e7b8e56294802",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.7 ms, sys: 19.1 ms, total: 50.8 ms\n",
      "Wall time: 54.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "AIMessage(content=\"Here's one:\\n\\nWhy couldn't the bicycle stand up by itself?\\n\\n(Wait for it...)\\n\\nBecause it was two-tired!\\n\\nHow was that? Do you want to hear another one?\", id='run-465fd061-b6a3-4fd5-a7d0-7c6613a59829-0')"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# The first time, it is not yet in cache, so it should take longer\n",
    "cf_llm_openai.invoke(\"Tell me a joke\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T07:30:27.269875Z",
     "start_time": "2024-07-08T07:30:27.214999Z"
    }
   },
   "id": "8273da11bdbb1ab9",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.6 ms, sys: 6.7 ms, total: 38.3 ms\n",
      "Wall time: 5.75 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "AIMessage(content=\"Here's one:\\n\\nWhy couldn't the bicycle stand up by itself?\\n\\n(Wait for it...)\\n\\nBecause it was two-tired!\\n\\nHow was that? Do you want to hear another one?\", id='run-720a2ec6-b4ac-4e10-b01b-38a2b9bebb28-0')"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 在这个句子中添加一些空格然后再提问\n",
    "cf_llm_openai.invoke(\"Tell me a   joke\")\n",
    "# 又会重新执行 \n",
    "# Why does the extra space cause the cache miss??"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T07:31:39.962231Z",
     "start_time": "2024-07-08T07:31:34.216297Z"
    }
   },
   "id": "482d715928654edc",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "engine = create_engine(\"sqlite:///.cache.db\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T07:32:57.682447Z",
     "start_time": "2024-07-08T07:32:57.678147Z"
    }
   },
   "id": "8dc0570903599ccb",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMKeyView(['prompt', 'llm', 'idx', 'response'])\n",
      "('[{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"messages\", \"HumanMessage\"], \"kwargs\": {\"content\": \"Tell me a joke\", \"type\": \"human\"}}]', '{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"chat_models\", \"openai\", \"ChatOpenAI\"], \"kwargs\": {\"model_name\": \"@cf/meta/llama-3-8b-instruct\", ... (485 characters truncated) ... }, {\"id\": 2, \"type\": \"schema\", \"data\": \"ChatOpenAIOutput\"}], \"edges\": [{\"source\": 0, \"target\": 1}, {\"source\": 1, \"target\": 2}]}}---[(\\'stop\\', None)]', 0, '{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"output\", \"ChatGeneration\"], \"kwargs\": {\"text\": \"Here\\'s one:\\\\n\\\\nWhy couldn\\'t the b ... (417 characters truncated) ... ? Do you want to hear another one?\", \"type\": \"ai\", \"id\": \"run-465fd061-b6a3-4fd5-a7d0-7c6613a59829-0\", \"tool_calls\": [], \"invalid_tool_calls\": []}}}}')\n",
      "('[{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"messages\", \"HumanMessage\"], \"kwargs\": {\"content\": \"Tell me a   joke\", \"type\": \"human\"}}]', '{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"chat_models\", \"openai\", \"ChatOpenAI\"], \"kwargs\": {\"model_name\": \"@cf/meta/llama-3-8b-instruct\", ... (485 characters truncated) ... }, {\"id\": 2, \"type\": \"schema\", \"data\": \"ChatOpenAIOutput\"}], \"edges\": [{\"source\": 0, \"target\": 1}, {\"source\": 1, \"target\": 2}]}}---[(\\'stop\\', None)]', 0, '{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"output\", \"ChatGeneration\"], \"kwargs\": {\"text\": \"Here\\'s one:\\\\n\\\\nWhy couldn\\'t the b ... (417 characters truncated) ... ? Do you want to hear another one?\", \"type\": \"ai\", \"id\": \"run-720a2ec6-b4ac-4e10-b01b-38a2b9bebb28-0\", \"tool_calls\": [], \"invalid_tool_calls\": []}}}}')\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as connection:\n",
    "\n",
    "    rs = connection.exec_driver_sql('select * from full_llm_cache')\n",
    "    print(rs.keys())\n",
    "    for row in rs:\n",
    "        print(row)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T07:32:59.026583Z",
     "start_time": "2024-07-08T07:32:59.019284Z"
    }
   },
   "id": "a1c65ff55de0ad3e",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a589a83031ac7747"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
